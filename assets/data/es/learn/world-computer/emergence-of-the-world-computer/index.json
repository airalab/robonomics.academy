{"hash":"ebf92df2790a8f2dc659c241c969d5c9f2c95e48","data":{"course":{"id":"6eeb69a9dbb9e31ce4c73f1e94a6f796","title":"Parte 3: Emergencia de la Computadora Mundial","description":"En la tercera parte titulada \"Emergencia de la Computadora Mundial,\" intentaremos, capa por capa, recrear la implementación de ingeniería de la computadora mundial utilizando ejemplos de Ethereum y Polkadot, como antes.","content":"\nEn la tercera parte titulada \"Emergencia de la Computadora Mundial,\" intentaremos, capa por capa, recrear la implementación de ingeniería de la computadora mundial utilizando ejemplos de Ethereum y Polkadot, como antes.\n\nComencemos con Ethereum. Ethereum comenzó en 2015 con un estado que puede caracterizarse como una combinación del algoritmo de consenso de prueba de trabajo, lo que permite que la computadora mundial exista en un estado descentralizado (como se discutió en la Parte 2). Además, se introdujo la Máquina Virtual Ethereum (EVM), que sirve como una máquina computacional completa de Turing. Juntos, estos dos elementos formaron la primera versión de la computadora mundial, a veces referida como precursora. En este contexto, comenzaron a surgir aplicaciones descentralizadas, o contratos inteligentes.\n\nDurante los próximos 5 años, Ethereum vivió una vida relativamente inalterada, experimentando algunos ajustes de ingeniería, como un aumento continuo en los límites de gas, con la excepción de eventos como el fork de Shanghai. Especialmente, durante el segundo DEFCON celebrado en Shanghai, un ataque de denegación de servicio explotó una función en la máquina virtual que consumía gas mínimo pero desencadenaba cálculos significativos en la red de Ethereum. Esto llevó a un desbordamiento de memoria, interrumpiendo efectivamente un nodo completo de Ethereum. Este incidente destaca los detalles intrincados que surgen al tratar con una solución grande y abstracta como la creación de una máquina virtual.\n\nAvanzando, ocurrió un cambio significativo hacia finales de la década, particularmente en 2020, con la llegada de Ethereum 2.0. Sin embargo, Ethereum 2.0 ha sido descontinuado, y caracterizaría el verdadero avance como comenzando alrededor de 2019-2020. Durante este período, hubo un verdadero avance tecnológico en Ethereum, avanzando hacia el concepto de Ethereum 2.0. El momento de cambio de ingeniería en la arquitectura de Ethereum puede considerarse el evento conocido como \"la fusión,\" donde se combinaron las funcionalidades de la cadena de balizas. La fusión marcó un cambio significativo en el paradigma de Ethereum, llevándolo a un estado ligeramente diferente al que estaba en el tablero. El cambio real de ingeniería en la arquitectura de Ethereum puede asociarse con \"la fusión,\" donde se integraron las funcionalidades de la cadena de balizas. Para obtener una historia detallada de esto, puede consultar el sitio web ethereum.org, que proporciona un excelente artículo sobre la coexistencia de la cadena de bloques tradicional de Ethereum con la cadena de bloques paralela lanzada en 2015 y la Máquina Virtual Ethereum.\n\nCuando ocurrió la fusión, presenciamos una nueva representación arquitectónica, tanto a nivel de red como para nodos individuales interactuando con la red Ethereum. ¿Cuál fue el cambio real? Para muchos, la fusión significa la transición de prueba de trabajo a prueba de participación, lo cual es realmente significativo. Implica mayor eficiencia y ajuste fino, pero sigue siendo un ajuste relativo a uno de los parámetros. Sin embargo, el cambio interno más notable para cada cliente de red fue la división. Ya no había un cliente de red específico o una arquitectura monolítica. En su lugar, obtuvimos dos componentes de un solo nodo interactuando con la red Ethereum.\n\nLa primera parte, que etiqueté como \"cadena de balizas\" en el diagrama, representa esencialmente una imagen colectiva de todas las innovaciones que llegaron al cliente de Ethereum en el momento de la fusión. La segunda parte es la máquina virtual preservada. Sin embargo, también vale la pena agregar algo aquí. Los diálogos realmente comenzaron sobre reemplazar la máquina virtual, que estaba exclusivamente diseñada para trabajar con contratos inteligentes y contratos inteligentes en un lenguaje específico: Solidity. Esto se debe a que, para 2015, prácticamente no quedaban intérpretes para contratos inteligentes en idiomas que no fueran Solidity, y la arquitectura parecía algo unidireccional desde la perspectiva de un programador de Ethereum. Aprendes un fragmento de JavaScript en forma de Solidity, escribes código de contrato inteligente en él y obtienes tu DApp, como Uniswap, por ejemplo.\n\nDesde la aparición de una arquitectura de Ethereum más compleja, las discusiones han girado en torno a la idea de que la máquina virtual, que existía como un elemento algo monolítico desde 2015, también puede ser reemplazada en la nueva arquitectura. La conversación se centró en reemplazarla con algo como WebAssembly (Wasm) o una solución más interesante desde la perspectiva de escribir código para la computadora mundial. Podrías decir, \"Wasm con un signo de interrogación.\"\n\nDesde la perspectiva de la Cadena de Balizas, efectivamente opera con prueba de participación, pero lo más interesante es la inclusión de Gasper. Esto representa una modificación de las ideas originales sobre Casper. Casper, a menudo referido como el dispositivo de finalidad del fantasma amigable, fue introducido, quizás incluso tan temprano como en Defcon 3 o 4, e incluso tal vez discutido en Defcon 2, no recuerdo exactamente. Pero en la conferencia EthCC en París, que definitivamente tuvo lugar en 2018, Vlad Zamfir y Vitalik, desde diferentes salas, estaban discutiendo la aparición de Casper como un fantasma amigable, supervisando a los participantes en prueba de participación y acudiendo en ayuda de la red cuando un nodo se comporta mal. A partir de esta idea de Casper, surge Gasper. Sin profundizar demasiado en la terminología, el algoritmo de consenso experimenta un cambio, cambiando no solo en términos de simplicidad, sino también volviéndose más complejo, similar a Polkadot. Como mencioné anteriormente, Polkadot tiene dos algoritmos de consenso, Babe y Grandpa. De manera similar, con la funcionalidad de la Cadena de Balizas de Ethereum, lograr consenso y finalidad no es tan instantáneo. Involucra épocas, y la red opera en un escenario más complejo, alcanzando un estado que ya es algo dinámico, no congelado y es esencialmente tallado en piedra.\n\n¿Qué se puede agregar en relación con 2024? Para mí, fue una observación prolongada y un intento de entender si Ethereum finalmente implementaría el fragmentación o no. La fragmentación es la capacidad de existir no con una sola cadena de bloques, sino con múltiples cadenas de bloques dentro de una red. Mientras observaba la fusión y el surgimiento simultáneo de redes de Capa 2 (L2), surgieron preguntas en mi mente sobre si la fragmentación realmente se materializaría. La fragmentación me pareció interesante debido a su homogeneidad: tener múltiples cadenas que son casi idénticas, sin características específicas. Parecía ser un enfoque interesante, pero no tan flexible como un enfoque heterogéneo. En las redes L2, incluso hace varios años, pude ver la heterogeneidad de Ethereum, su capacidad para trabajar con varios tipos de cadenas de bloques más específicas. Me intrigaba la dirección que tomaría: si la fragmentación, con su homogeneidad, desplazaría las soluciones L2 o si las soluciones L2 con un enfoque heterogéneo saturarían la Cadena de Balizas y los nodos principales de la red Ethereum.\n\nHoy, en 2024, basándome en artículos en ethereum.org, parece que la fragmentación como concepto ha sido postergada, y el enfoque está en ayudar a diversas redes L2 a integrarse con la Cadena de Balizas y alinearse con la funcionalidad de la cadena principal, que ahora está dividida en dos elementos en la arquitectura de la red Ethereum.\n\nPor lo tanto, sin profundizar en los detalles de cómo están estructuradas las redes L2, aunque tocaremos ese tema cuando completemos la segunda parte del tablero, debemos imaginar que Ethereum es ahora una especie de Beacon Chain, un faro, una estrella guía para numerosas redes L2. Estas redes L2 pueden tener funcionalidades más específicas, ejecutando su lógica de acuerdo con un conjunto de funciones individuales. Esto se alinea un poco con la idea de una navaja suiza, no convirtiendo a Ethereum en una navaja suiza, pero las redes L2 están empezando a diferenciarse en arquitectura. Duplican la funcionalidad de la máquina de computación abstracta de Ethereum pero la realizan con costos de gas más bajos o dentro de su segmento específico. Algunos ya están pensando en ajustar y hacer más eficiente su capa L2, centrándose en capacidades funcionales específicas. Por lo tanto, en mi opinión, estamos presenciando la aparición de heterogeneidad en la computadora mundial que pretendía ser homogénea. También es esencial no olvidar que las aplicaciones descentralizadas (dApps) todavía existen dentro de la cadena principal, dentro de esa misma cadena que comenzó en 2015. Esto significa que durante la fusión, durante la transición al nuevo estado arquitectónico, no hubo borrado, no hubo eliminación de la historia anterior. Todas las aplicaciones descentralizadas y contratos inteligentes subyacentes a estas aplicaciones continuaron existiendo, y continúan existiendo hoy, y probablemente mañana. Esta es una cuestión que exploraremos utilizando Polkadot como ejemplo, pero aún se tiene la sensación de que será posible establecer una aplicación descentralizada en la Beacon Chain—dApps.\n\nEn resumen, imaginemos la implementación de ingeniería del Ethereum actual como una computadora mundial. Tenemos cada nodo de red que consta de dos partes. La primera capa es responsable de la Máquina Virtual Ethereum (EVM), la funcionalidad real de la máquina virtual o máquina Turing completa, si hablamos en términos teóricos. Quizás veamos la aparición de alternativas a la máquina virtual diseñada en 2015. Estas alternativas probablemente la superarán en términos de posibilidades de programación más abstractas que escribir contratos inteligentes en Solidity. Mientras tanto, los contratos inteligentes en Solidity siguen sintiéndose cómodos. Si desea escribir funcionalidades para la cadena principal de Ethereum sin crear ninguna infraestructura encima de Ethereum, sin descargar ningún cálculo para hacerlo más barato, y así sucesivamente, las aplicaciones descentralizadas que puede escribir como contratos inteligentes aún pueden alojarse en la cadena principal de Ethereum. Al mismo tiempo, ha surgido la funcionalidad de Beacon Chain, separando la lógica de consenso entre validadores del protocolo principal de la máquina de computación. Esto permite una flexibilidad adicional en cómo debería funcionar el consenso y cómo debería modificarse sin afectar a la máquina virtual en sí. El ejemplo de Shanghai y Defcon 2, donde un pequeño error de opcode causó un apagado de parte de la infraestructura, sugiere que sería bueno tener tales funcionalidades complejas separadas en dos partes.\n\n¿Qué es interesante acerca de la Beacon Chain? Es un algoritmo más complejo y completo para lograr la sincronización de la red y la finalización con la introducción de conceptos como \"época\", y la presencia de un fantasma que vive dentro de la red.\n\nPor último, lo importante a considerar ahora es que Ethereum está poniendo fin efectivamente a la homogeneidad, a la idea de tener cien blockchains idénticas trabajando con la misma máquina virtual, donde los contratos inteligentes escritos en Solidity pueden residir. En cambio, varios proyectos están proponiendo sus propias arquitecturas o llevando la misma máquina virtual más allá de los límites de la cadena principal. Alternativamente, están tratando de construir su aplicación más específica, que, a nivel de la cadena principal de Beacon Chain, es un contrato inteligente escrito en Solidity. Esta es la representación actual de Ethereum, que no se convirtió en Ethereum 2.0. Sigue siendo el mismo Ethereum—un proyecto que una vez comenzó con prueba de trabajo + máquina Turing completa, transformándose en esta arquitectura.\n\nAhora, echemos un vistazo a cómo Polkadot surgió y evolucionó en los últimos 5 años. Polkadot surgió cinco años después de Ethereum, nacido del equipo que desarrolló uno de los mejores clientes para Ethereum: Parity. Muchos podrían recordar su cliente web, que, en comparación con Geth y otras implementaciones, probablemente era mucho más agradable de trabajar, al menos desde la experiencia personal y la experiencia de los colegas.\n\nEn segundo lugar, Polkadot fue, en mi opinión, una extensión de ideas que Gavin Wood quería incorporar al desarrollo de Ethereum. En consecuencia, se podría decir que Ethereum, en algún momento, se dividió en dos conceptos.\n¿Qué teníamos cuando se lanzó Polkadot? Se puso en marcha la cadena de relevos. Curiosamente, ¿verdad? Cadena de baliza y cadena de relé. ¿Qué representó la cadena de relevos? Inicialmente, no había posibilidad de colocar una aplicación descentralizada allí, escribir un contrato inteligente para ella o cargar su código en WASM o Solidity. Nada de esto estaba disponible en el momento del primer bloque o en los primeros días de existencia de la cadena de retransmisión de Polkadot. No había forma de agregar su tiempo de ejecución, del cual hablaremos en breve, y no se basó en la prueba de participación; en cambio, utilizó prueba de autoridad. Esto permitió que ciertos nodos lanzados por los desarrolladores de Polkadot sobrevivieran los primeros meses o semanas mientras se podían lanzar ataques a la cadena o si esta se comportaba incorrectamente. Sin embargo, esto cambió rápidamente y la cadena de retransmisión pasó a ser prueba de participación.\n\nAl final, después de un par de meses de la existencia de la cadena de retransmisión sin ninguna funcionalidad de aplicación descentralizada, sin la capacidad de conectar su paracadena o red L2, sin capacidades de usuario, la red pasó de un estado de autoridad a prueba de participación. Esto dio a los desarrolladores la capacidad de cargar sus tiempos de ejecución.\n\nEn este punto, también es interesante discutir las diferencias entre el Ethereum de hoy y cómo está estructurada la parte central de Polkadot. Desde la perspectiva del corazón, que ya hemos discutido, la imagen será absolutamente la misma no solo para Ethereum y Polkadot, sino para cualquier proyecto que quiera presentarse como una máquina de computación abstracta. Sin embargo, desde un punto de vista de ingeniería y arquitectura, es fascinante observar Beacon Chain & Relay Chain. Aquí, tenemos una máquina virtual, que ha sido heredada desde 2015, pero se están proponiendo alternativas. En la cadena de retransmisión, hay la capacidad de cargar su tiempo de ejecución. El tiempo de ejecución es, de hecho, su máquina virtual. Por ejemplo, algunas paracadenas emulan completamente la Máquina Virtual Ethereum. Se escribe como un tiempo de ejecución, lo que significa que básicamente puedes cargar un análogo de la Máquina Virtual Ethereum al nivel de paracadena en Polkadot o escribir lógica más específica que funcione con cuatro o cinco funciones. Recuerda la parte uno sobre las ideas: puedes escribir tu navaja suiza, pero no requerirá crear toda la infraestructura. Puedes implementar funcionalidades específicas con ciertas funciones a nivel de tiempo de ejecución, ponerlo en la cadena de retransmisión de Polkadot y la inmutabilidad de este tiempo de ejecución será asegurada por los validadores de Polkadot.\n\n¿Qué sucede a continuación? A lo largo de aproximadamente un año, comienza a formarse una capa de paracadenas alrededor de la cadena de retransmisión. En términos de implementación de Ethereum, se podría decir que las redes L2 son bastante similares a las paracadenas. Sin embargo, hay una interesante distinción entre redes cruzadas que encuentro fascinante en Polkadot, y estoy tratando de entender mejor cómo se desarrollará, a saber, la segunda capa de validación y verificación de disponibilidad de datos. Después de un par de años, Polkadot toma una forma como esta. No es solo una cadena de retransmisión donde los validadores de prueba de participación protegen el tiempo de ejecución de futuras paracadenas; una capa adicional y crucial de validación de datos y verificación de disponibilidad emerge de las paracadenas.\n\nAl observar este diagrama, intenta notar las analogías que surgen y las diferencias en los detalles de implementación de ingeniería. Entonces, ¿qué representa esto y cómo se compara este esquema con Ethereum? Tenemos un proyecto L2, en este caso, con Polkadot, es una parachain. Una parachain también genera bloques de información, que luego van a la cadena de retransmisión para combinarse y liberar un bloque de cadena de retransmisión como la suma de todas las cabeceras, cabeceras y más cabeceras. La parachain recopila transacciones en un bloque utilizando collators, que no participan en la validación. No apuestan nada en la cadena de retransmisión; solo utilizan el tiempo de ejecución, que está en la cadena de retransmisión. Lo obtienen, lo aplican a las transacciones, realizan transiciones de estado necesarias, forman un bloque y, crucialmente, proporcionan una prueba de validez: un sello que contiene pruebas criptográficas de que el collator ensambló correctamente el bloque. Esta información va al anillo de validación externo de la cadena de retransmisión. En este anillo, hay validadores internos de Polkadot: collators de parachain. Nuevamente, no apuestan nada directamente desde el punto de vista de la cadena de retransmisión. Las implementaciones de parachain a veces introducen su consenso entre collators, y algunas no. Por ejemplo, en Robonomics, implementando una parachain, encontramos este paradigma más interesante, menos pesado y hace que la red sea más simple pero sigue siendo funcionalmente sustancial. Cualquier collator, sin llegar a un consenso con nadie, verificado por nosotros, puede proponer un bloque y alguna prueba a la capa externa. Es precisamente por esto que se proponen bloques, se ofrecen pruebas de validez del ensamblaje del bloque y hay un anillo externo. No necesitamos ningún consenso de los validadores de parachain. Cualquiera puede generar un bloque y enviarlo, y si este nodo del collator envía información incorrecta a los validadores de parachain en el anillo externo, el validador en este nivel lo rechazará. No pasará a la parte central. Pero digamos que el bloque fue proporcionado correctamente por el collator. Nuestras transacciones entraron; el collator las calculó, aplicando el tiempo de ejecución almacenado en la cadena de retransmisión, ejecutó todas las transiciones de estado, reunió alguna prueba de validez: validez del bloque ensamblado y la pasó al anillo externo de la cadena de retransmisión. Aquí, en cada época, que también es parte de la finalización, cada época tiene validadores de la cadena de retransmisión divergiendo en parachains. Algunos se quedan en el centro y otros van a parachains. Su número varía de 16 a 64 validadores, y esta cifra, creo, cambiará en la especificación: en algunos lugares más, en otros menos. Sin embargo, los validadores de parachain vuelven a verificar la información de un grupo seleccionado de validadores sobre todo lo que proviene del collator es correcto, que el trabajo se ha realizado de acuerdo con el tiempo de ejecución y que la prueba de validez es realmente válida. El segmento seleccionado de validadores de la cadena de retransmisión que ya tienen algo apostado responden, o mejor dicho, trinan entre ellos. Responden al productor principal de bloques seleccionado de la parachain, por así decirlo, diciendo:  \"Sí, estamos de acuerdo. No hay problemas. Puedes llevarlo a través de todo el anillo externo interior.\"\n\nY así, casi toda la información formada en los recolectores de paracadenas, con verificación en el anillo externo, entra en el interno. La parte inferior, no es que esté físicamente en la parte inferior, sigue constituyendo el anillo externo: disponibilidad de datos. Los datos comienzan a ser verificados en esta etapa, lo que significa que en el anillo externo, no solo se verifica la corrección del ensamblaje de bloques, sino que comienza el proceso de preparación para la distribución dentro de la red Polkadot, asegurando que la información del bloque no se pierda en el futuro. Aquí, precisamente, es lo que mencioné en la segunda parte sobre fragmentos, como CD RW. En esta etapa de preparación del bloque para transferirlo al anillo interno, la capa de disponibilidad de datos se forma como un servicio, algo que actualmente también intentan algunos proyectos en Ethereum. Algunos proyectos colocan información redundante adicional directamente en contratos inteligentes, necesaria para verificar lo que está sucediendo en la capa L2 y, si es necesario, sancionar o castigar a aquellos que lo hicieron incorrectamente. Es imposible superar el anillo externo sin distribuir información de bloque y sin volver a verificar docenas de nodos con apuestas realizadas bajo la suposición de que el tiempo de ejecución debe funcionar correctamente.\n\nAsí, la información que ha pasado por el anillo externo ya es bastante confiable, probablemente sí, se puede decir eso, y en el anillo interno, el trabajo se hace principalmente no con bloques de paracadenas, sino que sus encabezados de bloque se recopilan en un gran encabezado. Es decir, a partir de muchos encabezados, se ensambla un encabezado de un bloque de cadena de relevos: un mecanismo de vinculación en Shared Security, como se menciona en Polkadot, que garantiza la seguridad de las paracadenas. Se podría decir que las paracadenas son validadas y alcanzan un estado donde el servicio existe en una forma distribuida descentralizada en el anillo externo. En el anillo interno, la información que ha ingresado intenta unirse en un hiperbloque, que debería enlazar todo precisamente. No hay cálculos sucediendo allí; no hay recalculo de absolutamente todo. El ensamblaje del bloque final tiene lugar, por así decirlo, en la iteración actual del ordenador mundial, para poner un punto en la pregunta de si la transacción ha pasado en una paracadena particular. Debemos ensamblar un hiperbloque que contenga no toda la información de las paracadenas, sino que reúna todos los encabezados verificados en el anillo externo de las paracadenas en un bloque grande. Y así, nuestro ordenador mundial en Polkadot opera.\n\nEchemos otro vistazo a estos dos esquemas juntos: cadena de relé, cadena de faro, tiempo de ejecución, asegurado por prueba de participación, donde alguien apuesta sus fondos para validar que siempre realizarán su trabajo correctamente. Hay una máquina virtual donde también puedes apostar tus fondos, y si realizas alguna computación o transición de estado que no esté de acuerdo con la especificación de la Máquina Virtual de Ethereum, serás penalizado.\n\nEn Polkadot, hay una capa externa adicional, que parece ser una de las principales ventajas, tales como agradables ventajas de la implementación de ingeniería que, en mi opinión, deberían estar presentes aquí. Debería aparecer entre las redes L2 y la cadena de faro, que existe en Ethereum. Por cierto, algunos dicen que el término \"cadena de faro\" está desapareciendo de nuevo y es malinterpretado, pero realmente me gusta usarlo en analogía con la \"cadena de relé,\" un término del roadmap de Ethereum.\n\nEn Polkadot, hay una capa externa que permite, o mejor dicho, creo que se inventó para resolver muchos problemas que surgen cuando tienes L2 o un conjunto de blockchains que necesitan estar conectados. En esta capa se implementa un mecanismo de ingeniería para la distribución de información para que esté disponible en una red descentralizada. Se introducen algoritmos adicionales para verificar no solo la validez sino también la disponibilidad de información por parte de los validadores. Además, existe un mecanismo para asignar aleatoriamente una parte de los validadores de Polkadot a paracaídas específicas en cada época. Por lo tanto, no hay paracaídas de servicio de validadores iguales en cada época; se barajan y envían a diferentes paracaídas en cada época. Al transferir un bloque del anillo externo al interno, los validadores se vuelven a verificar en el camino y se coordinan con los asignados a la parachain. Actualmente este proceso no existe, pero creo que aparecerá en algún momento.\nY quizás el último punto sea sobre las alzadoras, que hoy en día se implementan de manera bastante interesante en las paracaídas. Pueden ser consenso o existir sin consenso, pero, de hecho, funciona. En cuanto a las preguntas sobre las redes L2 con secuenciadores descentralizados o cómo se generarán y verificarán los bloques antes de instalarse en la máquina virtual, estas son preguntas separadas para la implementación de Ethereum en un formato heterogéneo. En este día, en mi opinión, está bastante bien implementado en Polkadot. Sin embargo, esto no significa que Polkadot esté por delante de todo el planeta y nunca alcanzará a Ethereum. Aunque es esta arquitectura la que me atrae para seguir trabajando y esperar que Polkadot siga desarrollándose bien en términos de tecnologías porque no he visto nada parecido en todos los aspectos conectados.\n\nY quizás una historia más interesante en esta parte de la conferencia: hasta ahora, apenas podemos imaginar mensajes adecuados entre redes L2 en Ethereum. Tal vez me perdí algo en los documentos, pero cuando no tienes un anillo externo y problemas como los recolectores, paravalidadores y servicios de disponibilidad de datos no están resueltos, pensar en cómo pueden comunicarse dos capas L2 es un desafío. Sin embargo, en Polkadot, existe. Incluso horizontalmente, a través de la cadena de retransmisión, lo que significa que directamente, se puede enviar una transacción de forma segura desde una paracadena a otra, sin confiar en ningún puente entre estas dos paracadenas. Esta es otra funcionalidad crucial que probablemente necesitará implementarse a nivel de conexión de redes L2. Los contratos inteligentes en Ethereum se comunican bien. Hemos creado muchas cadenas de contratos inteligentes vinculados, donde uno activa otro. Con esto, no hay problema. Pero cuando decimos que casi todas las aplicaciones se están trasladando a la capa L2 en una red heterogénea, escucho que si vives en una área específica, no podrás salir. Eso no es así a nivel de paracadenas e implementación en Polkadot. Ambas arquitecturas merecen ser observadas, ya que, en mi opinión, la implementación de ingeniería sigue el camino principal de convertirse en una computadora global. Difieren ligeramente, pero hay muchas similitudes. Hay una enorme cantidad de trabajo de ingeniería en todas partes. Como vemos, la civilización humana, en forma de una multitud de investigadores, ingenieros y desarrolladores en crecimiento con recursos significativos para un mayor desarrollo, se está moviendo aproximadamente en la misma dirección desde las primeras etapas más pequeñas hasta probablemente algún futuro establecimiento de la computadora mundial, todo en las mismas pistas.\n","fileInfo":{"path":"es/learn/world-computer/emergence-of-the-world-computer.md","name":"emergence-of-the-world-computer"},"defaultName":"World computer in your home","lastUpdate":null}},"context":{}}