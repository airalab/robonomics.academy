{"hash":"f0f5c02be608963a98931b1ff3d7b952f1efb26f","data":{"course":{"id":"7c4b3fd5de22b11e5daf2d693edb7754","title":"Deel 3: Opkomst van de Wereldcomputer","description":"In het derde deel getiteld 'Opkomst van de Wereldcomputer', zullen we laag voor laag proberen de technische implementatie van de wereldcomputer opnieuw te creëren met behulp van voorbeelden van Ethereum en Polkadot, zoals eerder.","content":"\nIn het derde deel getiteld 'Opkomst van de Wereldcomputer', zullen we laag voor laag proberen de technische implementatie van de wereldcomputer opnieuw te creëren met behulp van voorbeelden van Ethereum en Polkadot, zoals eerder.\n\nLaten we beginnen met Ethereum. Ethereum begon in 2015 met een staat die kan worden gekarakteriseerd als een combinatie van het proof-of-work consensusalgoritme, waardoor de wereldcomputer in een gedecentraliseerde staat kon bestaan (zoals besproken in Deel 2). Daarnaast werd de Ethereum Virtual Machine (EVM) geïntroduceerd, die diende als een Turing-complete computationele machine. Samen vormden deze twee elementen de eerste versie van de wereldcomputer, soms aangeduid als een voorloper. Binnen deze context begonnen gedecentraliseerde applicaties, of slimme contracten, op te komen.\n\nIn de daaropvolgende 5 jaar leefde Ethereum een relatief onveranderd leven, onderging enkele technische aanpassingen, zoals een voortdurende toename van gaslimieten, met uitzondering van gebeurtenissen zoals de Shanghai fork. Tijdens de tweede DEFCON die in Shanghai werd gehouden, werd opgemerkt dat een denial-of-service-aanval een functie in de virtuele machine misbruikte die minimaal gas verbruikte maar aanzienlijke berekeningen op het Ethereum-netwerk activeerde. Dit leidde tot geheugenoverschrijding, waardoor effectief een hele Ethereum-node werd verstoord. Dit incident benadrukt de complexe details die naar voren komen bij het omgaan met een grote en abstracte oplossing zoals het creëren van een virtuele machine.\n\nVervolgens vond er een significante verschuiving plaats rond het einde van het decennium, met name in 2020, met de komst van Ethereum 2.0. Echter, Ethereum 2.0 is nu verouderd, en ik zou het echte keerpunt karakteriseren als beginnend rond 2019-2020. Tijdens deze periode vond er een echte technologische doorbraak plaats in Ethereum, met de overgang naar het concept van Ethereum 2.0. Het moment van technische verandering in de architectuur van Ethereum kan worden beschouwd als het evenement dat bekend staat als 'de merge', waarbij de functionaliteiten van de beacon chain werden gecombineerd. De merge markeerde een significante verschuiving in het paradigma van Ethereum, waarbij het werd overgezet naar een iets andere staat dan wat op het bord stond. De daadwerkelijke technische verandering in de architectuur van Ethereum kan worden geassocieerd met 'de merge', waarbij de functionaliteiten van de beacon chain werden geïntegreerd. Voor een gedetailleerde geschiedenis hiervan kunt u verwijzen naar de website ethereum.org, die een uitstekend artikel biedt over de co-existentie van de traditionele Ethereum blockchain met de parallelle blockchain gelanceerd in 2015 en de Ethereum Virtual Machine.\n\nToen de samensmelting plaatsvond, zagen we een nieuwe architectonische representatie, zowel op netwerkniveau als voor individuele knooppunten die met het Ethereum-netwerk interageren. Wat was de werkelijke verandering? Voor velen betekent de samensmelting de overgang van proof-of-work naar proof-of-stake, wat inderdaad significant is. Het impliceert verhoogde efficiëntie en fijnafstemming, maar het is nog steeds een afstemming ten opzichte van een van de parameters. De meer opmerkelijke interne technische verandering voor elke netwerkclient was echter de splitsing. Er was niet langer een specifieke netwerkclient of een monolithische architectuur. In plaats daarvan kregen we twee componenten van een enkel knooppunt dat met het Ethereum-netwerk interageert.\n\nHet eerste deel, dat ik op het diagram 'beacon chain' heb genoemd, vertegenwoordigt in feite een collectief beeld van alle innovaties die in de Ethereum-client kwamen op het moment van de samensmelting. Het tweede deel is de behouden virtuele machine. Toch is het ook de moeite waard om hier iets aan toe te voegen. Er werden daadwerkelijk dialogen gestart over het vervangen van de virtuele machine, die exclusief was afgestemd op het werken met slimme contracten en slimme contracten in een specifieke taal - Solidity. Dit komt doordat er tegen 2015 praktisch geen interpreters meer waren voor slimme contracten in talen anders dan Solidity, en de architectuur leek enigszins eenzijdig vanuit het perspectief van een Ethereum-programmeur. Je leert een stukje JavaScript in de vorm van Solidity, schrijft er slim contractcode op en krijgt je DApp, zoals bijvoorbeeld Uniswap.\n\nSinds de opkomst van een complexere Ethereum-architectuur draaien discussies om het idee dat de virtuele machine, die vanaf 2015 als een enigszins monolithisch element bestond, ook kan worden vervangen in de nieuwe architectuur. Het gesprek verschoof naar het vervangen ervan door iets als WebAssembly (Wasm) of een interessantere oplossing vanuit het perspectief van het schrijven van code voor de wereldcomputer. Je zou kunnen zeggen, 'Wasm met een vraagteken.'\n\nVanuit het perspectief van de Beacon Chain werkt het inderdaad op proof-of-stake, maar wat interessanter is, is de inclusie van Gasper. Dit vertegenwoordigt een wijziging van de oorspronkelijke ideeën over Casper. Casper, vaak aangeduid als het vriendelijke spook finaliteitsgadget, werd geïntroduceerd, misschien zelfs al bij Defcon 3 of 4, en misschien zelfs besproken bij Defcon 2 - ik herinner me dat niet precies. Maar op de EthCC-conferentie in Parijs, die zeker plaatsvond in 2018, bespraken Vlad Zamfir en Vitalik, vanuit verschillende kamers, de opkomst van Casper als een vriendelijk spook, dat deelnemers aan proof-of-stake overziet en te hulp schiet van het netwerk wanneer een knooppunt zich misdraagt. Uit dit idee van Casper ontstaat Gasper. Zonder te diep in te gaan op de terminologie, ondergaat het consensusalgoritme een verschuiving, waarbij het niet alleen in termen van eenvoud verandert, maar ook complexer wordt, vergelijkbaar met Polkadot. Zoals ik eerder al zei, heeft Polkadot twee consensusalgoritmen, Babe en Grandpa. Op dezelfde manier, met de functionaliteit van de Ethereum Beacon Chain, is het bereiken van consensus en finaliteit niet zo onmiddellijk. Het omvat epochs, en het netwerk werkt volgens een complexer scenario, waarbij het een staat bereikt die al enigszins dynamisch is, niet bevroren, en in wezen in steen gebeiteld.\n\nWat kan er worden toegevoegd met betrekking tot 2024? Voor mij was het een langdurige observatie en een poging om te begrijpen of Ethereum uiteindelijk sharding zou implementeren of niet. Sharding is het vermogen om niet met een enkele blockchain te bestaan, maar met meerdere blockchains binnen één netwerk. Terwijl ik de samensmelting en de gelijktijdige opkomst van Layer 2 (L2) netwerken observeerde, rezen er vragen in mijn hoofd over of sharding daadwerkelijk zou materialiseren. Sharding leek interessant voor mij vanwege zijn homogeniteit - het hebben van meerdere ketens die bijna identiek zijn, zonder enige specifieke kenmerken. Het leek een interessante benadering, maar niet zo flexibel als een heterogene benadering. In L2-netwerken, zelfs enkele jaren geleden, kon ik de heterogeniteit van Ethereum zien, zijn vermogen om te werken met verschillende soorten meer specifieke blockchains. Ik was nieuwsgierig naar de richting die het zou inslaan - of sharding, met zijn homogeniteit, L2-oplossingen zou verdringen of dat L2-oplossingen met een heterogene benadering de Beacon Chain en de belangrijkste knooppunten van het Ethereum-netwerk zouden verzadigen.\n\nVandaag, in 2024, gebaseerd op artikelen op ethereum.org, lijkt het erop dat sharding als concept naar achteren is geschoven, en de focus ligt op het helpen van verschillende L2-netwerken om te integreren met de Beacon Chain en zich af te stemmen op de functionaliteit van de hoofdketen, die nu is verdeeld in twee elementen in de architectuur van het Ethereum-netwerk.\n\nDaarom, zonder in te gaan op de details van hoe L2-netwerken zijn gestructureerd - hoewel we daarop zullen ingaan wanneer we het tweede deel van het bord invullen - moeten we ons voorstellen dat Ethereum nu een soort Beacon Chain is, een baken, een leidende ster voor tal van L2-netwerken. Deze L2-netwerken kunnen meer specifieke functionaliteit hebben, hun logica uitvoeren volgens een reeks individuele functies. Dit is enigszins in lijn met het idee van een Zwitsers zakmes - niet van Ethereum een Zwitsers zakmes maken, maar L2-netwerken beginnen zich te differentiëren in architectuur. Ze dupliceren de functionaliteit van de abstracte rekenmachine van Ethereum, maar voeren deze uit met lagere gas kosten of binnen hun specifieke segment. Sommigen denken al na over het afstemmen en efficiënter maken van hun L2-laag, gericht op specifieke functionele mogelijkheden. Zo zijn we naar mijn mening getuige van de opkomst van heterogeniteit in de wereldcomputer die homogeen wilde zijn. Ook is het essentieel om niet te vergeten dat gedecentraliseerde applicaties (dApps) nog steeds bestaan binnen de hoofdblockchain, binnen dezelfde blockchain die in 2015 is gestart. Dit betekent dat tijdens de samenvoeging, tijdens de overgang naar de nieuwe architecturale staat, er geen uitwissing was, geen uitwissing van de vorige geschiedenis. Alle gedecentraliseerde applicaties en slimme contracten die aan deze applicaties ten grondslag liggen, bleven bestaan en bestaan vandaag nog steeds, en waarschijnlijk morgen ook. Dit is een vraag die we zullen verkennen aan de hand van Polkadot als voorbeeld, maar er is nog steeds het gevoel dat het mogelijk zal zijn om een gedecentraliseerde applicatie te vestigen in de Beacon Chain - dApps.\n\nSamengevat, laten we de technische implementatie van het huidige Ethereum als een wereldcomputer voorstellen. We hebben elk netwerkknooppunt bestaande uit twee delen. De eerste laag is verantwoordelijk voor de Ethereum Virtual Machine (EVM), de daadwerkelijke functionaliteit van de virtuele machine of Turing complete machine, als we in theoretische termen praten. Misschien zullen we de opkomst zien van alternatieven voor de virtuele machine die in 2015 is ontworpen. Deze alternatieven zullen waarschijnlijk deze overtreffen op het gebied van meer abstracte programmeermogelijkheden dan het schrijven van slimme contracten in Solidity. Ondertussen blijven slimme contracten in Solidity zich comfortabel voelen. Als je functionaliteit wilt schrijven voor de Ethereum hoofdchain zonder enige infrastructuur bovenop Ethereum te creëren, zonder enige berekeningen uit te besteden om ze goedkoper te maken, enzovoort, kunnen gedecentraliseerde applicaties die je als slimme contracten kunt schrijven nog steeds worden gehuisvest in de hoofdblockchain van Ethereum. Tegelijkertijd is de functionaliteit van de Beacon Chain ontstaan, waarbij de consensuslogica tussen validators wordt gescheiden van het hoofdprotocol van de rekenmachine. Dit biedt extra flexibiliteit in hoe consensus zou moeten werken en hoe het verder zou moeten worden aangepast zonder de virtuele machine zelf te beïnvloeden. Het voorbeeld van Shanghai en Defcon 2, waar een kleine opcode-fout een deel van de infrastructuur deed stilleggen, suggereert dat het goed zou zijn om dergelijke complexe functionaliteiten in twee delen te scheiden.\n\nWat interessant is aan de Beacon Chain? Het is een complexer, uitgebreider algoritme voor het bereiken van netwerksynchroniciteit en finalisatie met de introductie van concepten zoals 'epoch' en de aanwezigheid van een geest die binnen het netwerk leeft.\n\nTot slot is het nu belangrijk om te overwegen dat Ethereum effectief een einde maakt aan homogeniteit, aan het idee van honderd identieke blockchains die werken met dezelfde virtuele machine, waar slimme contracten geschreven in Solidity kunnen verblijven. In plaats daarvan stellen verschillende projecten hun eigen architecturen voor of dezelfde virtuele machine die voorbij de grenzen van de hoofdblockchain wordt genomen. Als alternatief proberen ze hun meer specifieke toepassing te bouwen, die op het niveau van de hoofdchain van de Beacon Chain een slim contract geschreven in Solidity is. Dit is de huidige representatie van Ethereum, dat geen Ethereum 2.0 is geworden. Het blijft hetzelfde Ethereum - een project dat ooit begon met proof of work + Turing complete machine, dat zich heeft getransformeerd in deze architectuur.\n\nNu gaan we eens kijken naar hoe Polkadot is ontstaan en geëvolueerd in de afgelopen 5 jaar. Polkadot kwam vijf jaar na Ethereum tot stand, voortgekomen uit het team dat een van de beste clients voor Ethereum ontwikkelde - Parity. Velen herinneren zich misschien hun webclient, die, in vergelijking met Geth en andere implementaties, waarschijnlijk veel prettiger was om mee te werken, althans vanuit persoonlijke ervaring en de ervaring van collega's.\n\nTen tweede was Polkadot naar mijn mening een uitbreiding van ideeën die Gavin Wood wilde integreren in de ontwikkeling van Ethereum. Bijgevolg zou je kunnen zeggen dat Ethereum op een gegeven moment in twee concepten is gesplitst.\nWat hadden we toen Polkadot werd gelanceerd? De estafetteketen werd gelanceerd. Interessant, toch? Bakenketting en relaisketting. Wat vertegenwoordigde de relaisketen? Aanvankelijk was er geen mogelijkheid om daar een decentrale applicatie te plaatsen, er een slim contract voor te schrijven of je code te uploaden in WASM of Solidity. Niets van dit alles was beschikbaar ten tijde van het eerste blok of de eerste paar dagen van het bestaan van de Polkadot-relaisketen. Er was geen manier om je runtime toe te voegen, waar we het binnenkort over zullen hebben, en het was niet gebaseerd op bewijs van inzet; in plaats daarvan gebruikte het een bewijs van autoriteit. Hierdoor konden bepaalde knooppunten die door Polkadot-ontwikkelaars waren gelanceerd de eerste maanden of weken overleven terwijl aanvallen op de keten konden worden gelanceerd of zich onjuist gedroegen. Dit werd echter snel veranderd en de estafetteketen ging over op een bewijs van inzet.\n\nUiteindelijk, na een paar maanden van het bestaan van de relay chain zonder enige gedecentraliseerde applicatiefunctie, zonder de mogelijkheid om je parachain of L2-netwerk aan te sluiten, zonder gebruikersmogelijkheden, maakte het netwerk de overgang van een autoriteitsstaat naar proof of stake. Dit gaf ontwikkelaars de mogelijkheid om hun runtimes te uploaden.\n\nOp dit punt is het ook interessant om de verschillen tussen het huidige Ethereum en hoe het centrale deel van Polkadot is gestructureerd te bespreken. Vanuit het perspectief van het hart, waar we het al over hebben gehad, zal het beeld absoluut hetzelfde zijn, niet alleen voor Ethereum en Polkadot, maar voor elk project dat zich wil presenteren als een abstracte rekenmachine. Vanuit een technisch en architectonisch oogpunt is het echter fascinerend om Beacon Chain & Relay Chain te observeren. Hier hebben we een virtuele machine, die is geërfd sinds 2015, maar er worden alternatieven voorgesteld. In de relay chain is er de mogelijkheid om je runtime te uploaden. De runtime is in feite je virtuele machine. Sommige parachains bootsen bijvoorbeeld volledig de Ethereum Virtual Machine na. Het is geschreven als een runtime, wat betekent dat je in feite een analoge Ethereum Virtual Machine naar het parachain-niveau in Polkadot kunt uploaden of meer specifieke logica kunt schrijven die werkt met vier of vijf functies. Herinner je deel één over de ideeën - je kunt je Zwitsers zakmes schrijven, maar het vereist niet het creëren van de hele infrastructuur. Je kunt specifieke functionaliteit implementeren met bepaalde functies op het runtimeniveau, het in de Polkadot relay chain plaatsen en de onveranderlijkheid van deze runtime zal worden gegarandeerd door Polkadot validators.\n\nWat gebeurt er vervolgens? In de loop van ongeveer een jaar begint zich een laag parachains te vormen rond de relay chain. In termen van Ethereum-implementatie zou je kunnen zeggen dat L2-netwerken vrij vergelijkbaar zijn met parachains. Er is echter één interessant cross-network onderscheid dat ik fascinerend vind in Polkadot, en ik probeer verder te begrijpen hoe het zich zal ontwikkelen - namelijk, de tweede laag van validatie en data beschikbaarheidscontroles. Na een paar jaar krijgt Polkadot een vorm als deze. Het is niet alleen een relay chain waar proof-of-stake validators de runtime van toekomstige parachains beschermen; er ontstaat een aanvullende en cruciale laag van data-validatie en beschikbaarheidscontrole vanuit parachains.\n\nTerwijl je naar dit diagram kijkt, probeer de analogieën op te merken die ontstaan en de verschillen in technische implementatiedetails. Dus, wat vertegenwoordigt dit en hoe verhoudt dit schema zich tot Ethereum? We hebben een L2-project, in dit geval met Polkadot, het is een parachain. Een parachain genereert ook informatieblokken, die vervolgens naar de relay chain gaan om te worden gecombineerd en een relay chain-blok vrij te geven als de som van alle headers, headers en meer headers. De parachain verzamelt transacties in een blok met behulp van collators, die niet betrokken zijn bij validatie. Ze staken niets in de relay chain; ze gebruiken alleen de runtime, die in de relay chain zit. Ze halen het op, passen het toe op transacties, voeren noodzakelijke staatsovergangen uit, vormen een blok en, cruciaal, leveren bewijs van geldigheid - een stempel met cryptografische bewijzen dat de collator het blok correct heeft samengesteld. Deze informatie gaat naar de externe validatiering van de relay chain. In deze ring bevinden zich interne validators van Polkadot - parachain collators. Nogmaals, ze staken niets rechtstreeks vanuit het oogpunt van de relay chain. Parachain-implementaties introduceren soms hun consensus onder collators, en sommige niet. Bijvoorbeeld, in Robonomics, bij het implementeren van een parachain, vinden we dit paradigma interessanter, minder belastend, en het maakt het netwerk eenvoudiger terwijl het functioneel substantieel blijft. Elke collator, zonder consensus te bereiken met iemand - geverifieerd door ons - kan een blok voorstellen en wat bewijs naar de externe laag sturen. Daarom worden blokken voorgesteld, bewijzen van de geldigheid van de blokassemblage worden aangeboden, en er is een externe ring. We hebben geen consensus nodig van parachain validators. Iedereen kan een blok genereren en verzenden, en als deze node van de collator onjuiste informatie naar de parachain validators op de externe ring stuurt, zal de validator op dit niveau het afwijzen. Het zal niet doorgaan naar het centrale deel. Maar laten we zeggen dat het blok correct is verstrekt door de collator. Onze transacties zijn erin gekomen; de collator heeft ze berekend, de runtime toegepast die is opgeslagen in de relay chain, alle staatsovergangen uitgevoerd, wat bewijs van geldigheid verzameld - geldigheid van het samengestelde blok - en dit doorgegeven aan de externe ring van de relay chain. Hier, elke epoch, die ook de finalisatie omvat, heeft elke epoch validators van de relay chain die zich vertakken naar parachains. Sommigen van hen blijven in het midden, en de anderen gaan naar parachains. Hun aantal varieert van 16 tot 64 validators, en dit cijfer, geloof ik, zal veranderen in de specificatie - ergens meer, ergens minder. Parachain validators controleren opnieuw de informatie van een geselecteerde groep validators over alles wat afkomstig is van de collator correct is, dat het werk is uitgevoerd in overeenstemming met de runtime, en dat het bewijs van geldigheid inderdaad geldig is. Het geselecteerde segment van relay chain validators die al iets hebben ingezet, reageren, of liever gezegd, tjilpen onderling. Ze reageren op de gekozen hoofdblokproducent van de parachain, zogezegd, zeggend, \"Ja, we zijn het eens. Er zijn geen problemen. Je kunt het door de hele externe ring binnen dragen.\"\n\nEn dus komt bijna alle informatie die is gevormd op de parachain collators, met verificatie op de externe ring, de interne ring binnen. Het onderste deel, niet dat het fysiek onderaan staat, vormt nog steeds de externe ring - gegevensbeschikbaarheid. Gegevens beginnen op dit punt te worden gecontroleerd, wat betekent dat op de externe ring niet alleen de juistheid van de blokassemblage wordt geverifieerd, maar ook het proces van voorbereiding op distributie binnen het Polkadot-netwerk begint, waarbij wordt gegarandeerd dat de blokinformatie niet verloren gaat in de toekomst. Hier, precies, is wat ik noemde in het tweede deel over brokken, zoals CD RW. Op dit punt van blokvoorbereiding voor overdracht naar de interne ring wordt de gegevensbeschikbaarheidslaag gevormd als een service, iets dat momenteel ook wordt geprobeerd door sommige projecten in Ethereum. Sommige projecten voegen aanvullende redundante informatie rechtstreeks toe aan slimme contracten, die nodig zijn om te controleren wat er gebeurt op de L2-laag en, indien nodig, degenen die het verkeerd hebben gedaan te straffen. Het is onmogelijk om de externe ring te overwinnen zonder blokinformatie te distribueren en zonder tientallen knooppunten opnieuw te controleren met inzetten die zijn gedaan op de veronderstelling dat de runtime correct moet werken.\n\nDus, informatie die door de externe ring is gegaan, is al behoorlijk betrouwbaar, waarschijnlijk ja, je kunt dat zeggen, en op de interne ring wordt het werk voornamelijk gedaan niet met parachainblokken, maar hun blokkoppen worden verzameld in één grote kop. Dat wil zeggen, uit veel koppen wordt één kop van een relay chain-blok samengesteld - een mechanisme van koppeling in Shared Security, zoals vermeld in Polkadot, dat de beveiliging van parachains garandeert. Men zou kunnen zeggen dat parachains worden gevalideerd en een staat bereiken waarin de service bestaat in een gedistribueerde gedecentraliseerde vorm op de externe ring. In de interne ring probeert de informatie die is binnengekomen samen te komen in één hyperblok, dat alles precies moet verbinden. Er vinden geen berekeningen plaats; er is geen herberekening van absoluut alles. De samenstelling van het uiteindelijke blok vindt plaats, zogezegd, in de huidige iteratie van de wereldcomputer, om een punt te zetten achter de vraag of de transactie is geslaagd in een bepaalde parachain. We moeten een hyperblok samenstellen dat niet alle informatie van de parachains bevat, maar alle gecontroleerde koppen op de externe ring van parachains verzamelt in één groot blok. En zo werkt onze wereldcomputer in Polkadot.\n\nLaten we nog eens kijken naar deze twee schema's samen: relay chain, beacon chain, runtime, beveiligd door proof of stake, waar iemand zijn fondsen inzet om te valideren dat ze altijd correct zullen werken. Er is een virtuele machine waar je ook je fondsen kunt inzetten, en als je enige berekening of statusovergang uitvoert die niet in overeenstemming is met de specificatie van de Ethereum Virtual Machine, zul je worden gestraft.\n\nIn Polkadot is er een extra externe laag, wat een van de belangrijkste voordelen lijkt te zijn, zoals aangename voordelen van de technische implementatie die naar mijn mening hier aanwezig zouden moeten zijn. Het zou moeten verschijnen tussen L2-netwerken en de beacon chain, die in Ethereum bestaat. Overigens zeggen sommigen dat de term \"beacon chain\" weer aan het uitsterven is en verkeerd begrepen wordt, maar ik gebruik hem graag in analogie met de \"relay chain,\" een term uit de routekaart van Ethereum.\n\nIn Polkadot is er een externe laag die het mogelijk maakt, of beter gezegd, ik denk dat deze is uitgevonden om veel problemen op te lossen die zich voordoen als je L2 hebt of een reeks blockchains die met elkaar verbonden moeten worden. Op deze laag wordt een technisch mechanisme voor de distributie van informatie geïmplementeerd om deze beschikbaar te maken in een gedecentraliseerd netwerk. Er worden aanvullende algoritmen geïntroduceerd om niet alleen de geldigheid, maar ook de beschikbaarheid van informatie door validators te controleren. Bovendien is er een mechanisme om elk tijdperk willekeurig een deel van de Polkadot-validators toe te wijzen aan specifieke parachains. Het zijn dus niet dezelfde validators die elk tijdperk parachains bedienen; ze worden geschud en elk tijdperk naar verschillende parachains gestuurd. Bij het overbrengen van een blok van de externe ring naar de interne worden de validators onderweg opnieuw gecontroleerd en gecoördineerd met de validators die aan de parachain zijn toegewezen. Momenteel bestaat dit proces niet, maar ik denk dat het ooit zal verschijnen.\nEn misschien gaat het laatste punt over collators, die tegenwoordig behoorlijk interessant worden geïmplementeerd in parachains. Ze kunnen consensus zijn of bestaan zonder consensus, maar in feite werkt het. Wat betreft vragen in L2-netwerken met gedecentraliseerde sequencers of hoe blokken zullen worden gegenereerd en geverifieerd voordat ze zich in de virtuele machine nestelen: dit zijn afzonderlijke vragen voor de implementatie van Ethereum in een heterogeen formaat. Op deze dag is het naar mijn mening behoorlijk goed geïmplementeerd in Polkadot. Dit betekent echter niet dat Polkadot voorop loopt op de hele planeet, en Ethereum nooit zal inhalen. Hoewel het deze architectuur is die mij aantrekt om te blijven werken en ik hoop dat Polkadot zich goed zal blijven ontwikkelen op het gebied van technologieën, omdat ik zoiets nog niet heb gezien in alle daarmee samenhangende aspecten.\n\nEn misschien nog een interessant verhaal in dit deel van de lezing: tot nu toe kunnen we ons nauwelijks voorstellen dat er juiste cross-chain berichten zijn tussen L2-netwerken in Ethereum. Misschien heb ik iets gemist in de papers, maar als je geen externe ring hebt en problemen zoals collators, paravalidators en gegevensbeschikbaarheidsdiensten niet zijn opgelost, is het uitdagend om na te denken over hoe twee L2-lagen kunnen communiceren. Toch bestaat dit in Polkadot. Zelfs horizontaal, via de relay chain, wat betekent dat men direct een transactie veilig van de ene parachain naar de andere kan sturen, zonder enige bruggen tussen deze twee parachains te vertrouwen. Dit is een andere cruciale functionaliteit die waarschijnlijk op het niveau van het verbinden van L2-netwerken moet worden geïmplementeerd. Slimme contracten in Ethereum communiceren goed. We hebben veel ketens van gekoppelde slimme contracten gecreëerd, waarbij de ene de andere activeert. Hiermee is er geen probleem. Maar als we zeggen dat bijna alle toepassingen naar de L2-laag in een heterogeen netwerk verhuizen, hoor ik dat als je in een specifiek gebied woont, je niet kunt ontsnappen. Dat is niet het geval op het niveau van parachains en implementatie in Polkadot. Beide architecturen zijn het waard om in de gaten te houden, aangezien naar mijn mening de technische implementatie het mainstream pad volgt om een wereldwijde computer te worden. Ze verschillen enigszins, maar er zijn veel overeenkomsten. Er is een enorme hoeveelheid technisch werk overal. Zoals we zien, beweegt de menselijke beschaving, in de vorm van een veelheid van onderzoekers, ingenieurs en groeiende ontwikkelaars met aanzienlijke middelen voor verdere ontwikkeling, ruwweg in dezelfde richting vanaf het kleinste beginstadium tot waarschijnlijk een toekomstige oprichting van 's werelds computer, allemaal op dezelfde sporen.\n","fileInfo":{"path":"nl/learn/world-computer/emergence-of-the-world-computer.md","name":"emergence-of-the-world-computer"},"defaultName":"World computer in your home","lastUpdate":null}},"context":{}}