{"hash":"8ef03bb5d0758af9cf9521a2138c5ca6b002a78d","data":{"course":{"id":"2743047595228220b5b139c6080e4a41","title":"Deel 4: Het Pad van een Nieuw Blok van Informatie in de Wereldcomputer","description":"Het vierde en laatste deel van onze lezing is \"De Wereldcomputer in Jouw Huis.\" Hierna zal ik beginnen met het opnemen van screencasts voor het praktische gedeelte van de sessies.","content":"\nHet vierde en laatste deel van onze lezing is \"De Wereldcomputer in Jouw Huis.\" Hierna zal ik beginnen met het opnemen van screencasts voor het praktische gedeelte van de sessies.\n\nNu zullen we proberen bijna alle theorie die we tot nu toe hebben behandeld samen te vatten in termen van één proces. Het proces dat het pad van een informatieblok in de wereldcomputer beschrijft. Laten we opnieuw beginnen door terug te keren naar het thema van web3 en het concept van blockchain. De term \"blok\" of \"informatieblok\" kan als identiek worden beschouwd wanneer we ons terugtrekken van de laatste 10 jaar en een meer algemene theorie nemen, zoals onderzocht in de vorige delen van de lezingen. Het concept van een \"blok van informatie\" komt overeen met web3, maar niet noodzakelijkerwijs met blockchain. Zelfs zonder enige cryptoprojecten moeten we begrijpen dat wanneer we de theorie van de wereldcomputer vormgeven zonder te verwijzen naar de vorming van informatieblokken, het momenteel uitdagend is om andere modellen voor te stellen. Dus, we zullen het pad van een informatieblok in de hele wereldcomputer overwegen, niet omdat het blockchain is, maar omdat er op dit moment geen andere manieren zijn om het bestaan van de wereldcomputer te conceptualiseren dan door informatie te verwerken in specifieke porties.\n\nInformatieblok = blok in web3, maar zonder blockchain en zonder enige invloed van cryptoprojecten. We moeten momenteel de vorming van informatieblokken overwegen bij het bespreken van de theorie van de wereldcomputer. Laten we nu doorgaan naar het eerste punt. Ik heb geprobeerd om nauwe analogieën uit het dagelijks leven te vinden om het pad van een informatieblok in de wereldcomputer te illustreren. De analogie die ik heb gekozen is de beweging van een bus op een route. Ons eerste ontmoetingspunt is het busstation.\n\nIk heb transacties in het roze gemarkeerd als kleine stippen. Laten we ons een typische bushalte voorstellen waar mensen samenkomen en wachten op een bus die volgens een schema rijdt. Als we de drukte van grote steden niet meerekenen, waar bussen altijd te laat zijn, weet iedereen in de wereld over het algemeen dat de trein van dorp A naar dorp B altijd rond 7:15 uur aankomt. Transacties die gebruikers naar de wereldcomputer willen sturen verzamelen zich bij een bepaalde bushalte en wachten tot de bus arriveert.\n\nDit is hoe ons blok wordt gevormd. Stel je voor: de bus arriveert en elke persoon begint één voor één aan boord te gaan, neemt plaats. De bus volgt dan zijn route. In ons geval overwint het blok van informatie de eerste grens. Onze transacties, in enige vorm, zijn in de bus gesetteld en hebben de initiële barrière overwonnen. Ik zal voornamelijk terminologie van Polkadot gebruiken, en het derde deel zou het concept van de wereldcomputer beter moeten hebben uitgelegd in de vergelijking tussen Ethereum en Polkadot. Mijn persoonlijke mening, en waarschijnlijk zou de meerderheid van de ingenieurs vandaag het ermee eens zijn, is dat de representatie van een heterogene multicentrische wereldcomputer beter geïmplementeerd is in Polkadot. We zullen echter nog steeds de termen doornemen die zijn geërfd van Ethereum, maar tegen het einde van dit deel van de lezing.\n\nWat is de lijn die de bushalte scheidt van de verdere beweging van de bus? Deze lijn vertegenwoordigt de collators van het netwerk - deelnemers aan de netwerknodes die transacties verzamelen. Je kunt een collator niet zien als een buschauffeur maar als een controller die bij de bushalte blijft. Met andere woorden, deze controller controleert of je een kaartje hebt wanneer je de bus instapt. Het controleert niet opnieuw in de database hoe geldig het kaartje is, maar kijkt naar de basisparameters van het kaartje en controleert of alles in orde lijkt. In werkelijkheid voeren collators bijna alle vereiste berekeningen uit, verifiëren het kaartnummer en andere gegevens, maar ze zijn niet verplicht om te garanderen dat de controle correct is uitgevoerd. Daarom zijn collators controllers die bij de bushalte blijven, voornamelijk zorgen voor het instappen van passagiers, het plaatsen en het verder sturen van de bus langs de route.\n\nVoorbij de getrokken grens betreden we het eerste validatiegebied waar paravalidators zich bevinden. Dit zijn validators van het hele ecosysteem, het hele netwerk, specifiek toegewezen voor een bepaalde tijd om elke transactie te controleren en zo daadwerkelijke berekeningen uit te voeren in de wereldcomputer. Ons nog niet volledig gevormde blok van informatie is gemarkeerd met een stippellijn. Het is nog steeds een kandidaat-blok van informatie omdat het nog geen enkele daadwerkelijke verificatie heeft ondergaan. De collator, die het blok van informatie heeft verzameld en de transacties bij de ingang heeft gecontroleerd, neemt op geen enkele manier deel aan het beveiligen van de cyberbeveiliging van de uitgevoerde berekeningen. Zijn taak is alleen om alle transacties te plaatsen en het eerste blok te vormen. In deze fase begint de transformatie van een kandidaat naar een echt blok van informatie.\n\nIk heb het in drie delen verdeeld, maar vergat er nog een. Laten we vier delen van dit kandidaatblok overwegen. Het bovenste deel, bekend bij gebruikers van verschillende web3-toepassingen als de header of blokkop, is de essentie, het meest populaire stuk informatie dat circuleert en wordt weerspiegeld vanuit de blokverkenner naar de consoleclients van alle knooppunten die mijnen, staken, enz. De header is een sleutelelement van het blok, maar wordt praktisch gevormd in de laatste fase op dit punt.\n\nTen eerste hebben we onze daadwerkelijke verzoeken voor statusovergangen of berekeningen. Er is een lijst van veranderingen die moeten worden aangebracht: A omzetten naar A', B naar B', C naar C', waarbij een reeks algoritmen op hen wordt toegepast. Hiervoor zullen we nu onmiddellijk een andere grens bouwen en er voorbij gaan om dit deel van het werk uit te voeren, en dan pas verder gaan. Al bij de blokvoorbereidingsfase moeten we de tweede grens binnen de wereldcomputer oversteken om naar de algoritmen te gaan die moeten worden toegepast om het blok voor te bereiden. Zoals ik al eerder zei, doet de controller bij de bushalte hier theoretisch hetzelfde, maar daar zou ik niet veel aandacht aan besteden. De blokvoorbereidingsfase, vooral wanneer we tegelijkertijd voorbeelden bespreken van Polkadot en Ethereum als wereldcomputer, verschillen ze iets en tonen ons de onbeduidendheid van controles in deze fase omdat het precies op de tweede stap is, na het passeren van de eerste grens en het ontvangen van het blok van informatie van collators, dat de aandachtswaardige berekeningen van deze wereldcomputer beginnen.\n\n\nOm deze berekeningen uit te voeren, kan de validator op dit moment alleen naar de relay chain, de centrale database, gaan en daar de algoritmes uit de runtime halen. In het geval van Ethereum waren het dezelfde virtuele machines in het vorige architecturale concept, die konden worden toegepast, dus er was geen noodzaak om ergens heen te gaan. Bijna elke node had een volledige kopie van de algoritmes die konden worden toegepast. Maar in termen van een heterogeen netwerk, waar elk segment of elke individuele chain zijn eigen set algoritmes kan hebben, moet een validator, voordat hij daadwerkelijk alle overgangen uitvoert, berekeningen verkregen in de vorm van een blokkandidaat van de collator, raadplegen. Hij moet de relay chain raadplegen, de main blockchain in het netwerk raadplegen en daar de benodigde algoritmes vandaan halen, ze toepassen en overgangen uitvoeren.\n\nTijdens de uitvoering van berekeningen wordt tegelijkertijd een Merkle tree gevormd, en we zullen er niet te lang bij stilstaan omdat Merkle trees niet zo ingewikkeld zijn vanuit het perspectief van de informatica. Toch merk ik op dat om te begrijpen hoe ze toegepast worden in de techniek en in de architectuur van een project, hoe ze worden toegepast, niet alleen door te lezen op Wikipedia, je een beetje je hoofd moet breken, voorbeelden moet bedenken. In dit voorbeeld zullen we er niet te diep op ingaan, maar ik denk dat voor degenen die al bekend zijn met enkele basisdefinities, die hebben gelezen over Merkle trees, het iets duidelijker zal worden over hoe en op welke momenten een andere Merkle tree wordt samengesteld. De Merkle tree wordt gevormd wanneer we daadwerkelijk berekeningen uitvoeren en er outputwaarden verschijnen. Deze outputwaarden worden verpakt in een binaire boomstructuur, vervolgens wordt de toevoeging tussen hen uitgevoerd in de taal van de informatica, en de bovenste knoop bereikt de header. Laten we het aanduiden met een grote letter \"H.\" Het is een klein en aangenaam aspect om dergelijke schema's te overwegen.\n\nIn dit schema kunnen we opmerken hoe de blokkop eigenlijk gerelateerd is aan de berekeningen die binnenin worden uitgevoerd. Laten we nog eens kijken - onze blokkandidaat kwam van de collator. Er is een reeks transacties die moeten worden uitgevoerd, berekeningen uitvoeren. De validator ging door een andere interne grens, nog een, achter de algoritmes, paste ze toe en registreerde alle resultaten op het laagste niveau van de Merkle tree. De andere knooppunten zijn in wezen systemisch. Ze komen niet voort uit enige data; ze komen niet van ergens. Op het tweede niveau komt het knooppunt niet voort uit enige informatie. Het wordt verkregen door waarden in deze twee bladeren op te tellen, en wanneer we omhoog gaan, krijgen we alleen de wortel van deze boom, die voldoende is om alle outputwaarden te beschermen. We krijgen niet dezelfde header als we een van deze berekeningen wijzigen. En dit is een van de magische en eenvoudige kenmerken, zoals op hash-georiënteerde opslag, van hoe we een hele blok informatie kunnen beschermen door alleen te praten over één header. Daarom zijn headers zo belangrijk en spelen ze zelfs een hoeksteenrol in architecturen wanneer we overgaan van één chain of één virtuele machine naar velen gecombineerd in het netwerk. Het is voldoende voor ons om de beveiliging van het opslaan van headers te waarborgen om er zeker van te zijn dat alle transacties die zijn uitgevoerd in de blokvoorbereidingsfase correct zijn uitgevoerd en niet kunnen worden vervangen.\n\nEn er is nog steeds één veld oningevuld. In het proces van het voorbereiden van het blok informatie, is het het veld van de auteur, dat wil zeggen de validator die daadwerkelijk alle wijzigingen heeft uitgevoerd, de Merkle tree heeft voorbereid en de header heeft opgenomen. Aangezien we een voorbeeld bekijken met de bus die langs de route van de halte beweegt, laten we de validator een \"controller\" noemen die rechtstreeks de bus in gaat, elke stoel passeert, elke persoon benadert, controleert wat er echt op hun tickets staat, een markering maakt, valideert het en plaatst dienovereenkomstig hun handtekening. De controller, bijvoorbeeld nummer 134, wat natuurlijk betekent dat elke validator een unieke identificatie heeft, hun adres, en we het hier ook op de een of andere manier uniek hebben hernoemd.\n\nEn het lijkt erop dat we op dit punt onze blokgrenzen hadden kunnen markeren en dikker hadden kunnen maken, maar nee, en dit is een van de interessante veranderingen die zich in de afgelopen 5 jaar hebben voorgedaan op het gebied van gedecentraliseerde ecosystemen, namelijk de verschuiving van proof of work. Toen de validators van het netwerk, destijds mijnwerkers, nooit iets met elkaar hoefden af te stemmen. Je produceerde een blok en stuurde het naar het netwerk en ging verder. In feite was het geen consensus van overeengekomen instemming. Het was een consensus van duidelijke overeenstemming met het feit dat zich had voorgedaan. Wat interessante veranderingen zijn wanneer de architectuur complexer wordt, en we zijn dichterbij gekomen van een eenvoudige rekenmachine zoals Bitcoin met een grootboek naar een daadwerkelijke virtuele computer, is dat op elk niveau de connectiviteit van de deelnemers die zorgen voor beveiliging en blokproductie is toegenomen. Omdat, in feite, niemand die zijn inzet riskeert, degene die deze beveiliging waarborgt en wil verdienen door uw transacties te verwerken, iets te verliezen heeft, in tegenstelling tot proof of work. Bij proof of work heb je de apparatuur gekocht, ja, je hebt er geld in gestoken, je hebt elektriciteit verbruikt, maar er is eigenlijk geen bescherming tegen het feit dat je het netwerk kunt aanvallen met je kracht, dezelfde 51% aanval, waar iemand met veel mijnwerkers kan proberen de keten te herschrijven.\n\nNu praten we over bewijs van belang, waarbij al een storting is gedaan, en als je iets verkeerd doet, wordt er een deel van afgetrokken als straf. Alle knooppunten, absoluut, in alle architecturen die ik momenteel observeer, begonnen mechanismen voor berichtenuitwisseling tussen validators snel te verschijnen in de fase van blokvoorbereiding. In Polkadot is het niet anders. Elke validator van een afzonderlijke parachain die een blok verzamelt, kent de adressen of heeft al contact gelegd met nog eens 15-63 validators die met jou op dit tijdperk zijn, gedurende een bepaalde tijdelijke periode, als validators, en elk van hen wordt op een gegeven moment willekeurig een blokproducent. Maar benoemd worden als producent doet geen afbreuk aan een zeer belangrijk onderdeel van dit proces. Je stopt niet met communiceren met de andere deelnemers. Er is altijd een pool van validators toegewezen aan een specifiek tijdperk, aan een bepaald tijdsinterval, voor het valideren van een bepaalde parachain of segment van de wereldcomputer. Ongeacht of je een validator-controller bent die specifiek is toegewezen om het volgende blok te produceren in de wereldcomputer van dit segment, blijf je toch in contact met de andere validators, en heb je voortdurend contact met hen.\n\nWaarom is dit constante contact noodzakelijk? Het blijkt vrij eenvoudig te zijn. We willen niet, wanneer we naar het binnenste deel gaan, bang zijn of ons zorgen maken dat we een van de operaties verkeerd hebben uitgevoerd. Zo verrassend als het ook mag lijken, is het gunstig voor elke validator, voordat ze verder gaan, eerst naar hun collega's die zijn toegewezen aan validatie te gaan en hen vragen om de berekeningen te controleren. Deze controle is informeel, dus zelfs als we geen logging gebruiken in een onveranderlijke database van verzoeken om verificatie en de resultaten van deze verificatie, verzamelt de aangewezen controller, na met de groep validators te hebben gesproken, nog steeds aanvullende reacties van alle validators die zijn toegewezen aan deze parachain of netwerksegment. Samen met aanvullende bevestigingen gaat de controller verder naar de volgende fase. Maar zelfs hier is het niet helemaal zo eenvoudig. Op dit punt moet nog een ander proces worden uitgevoerd. Het is belangrijk op te merken dat op dit punt ons informatieblok nog steeds een kandidaat-blok is, en de afwikkeling van informatie al plaatsvindt in de opslag. Noch aan het einde, noch nadat we het blok hebben gemaakt en verzegeld en het met een archiver in het laatste deel hebben bevestigd, namelijk hier, in dit middelste deel waar alle berekeningen daadwerkelijk worden uitgevoerd, wordt de informatie opgeslagen in de opslag. Daarom zorgt onze controller, naast het praten met hun collega's, er ook voor dat de gegevens worden opgeslagen in een opslag, wat ook behoorlijk metafysisch is omdat op het moment dat je communiceert met andere validators, deze opslag wordt gevuld. Hoe wordt dit gecontroleerd? We zullen verder moeten gaan naar de volgende fase.\n\nSamenvattend, om het middelste deel te voltooien, laten we nog eens kijken. We hebben nog steeds alleen een kandidaatblok aan het begin. Ja, alle transacties worden ergens bij de bushalte ruwweg berekend, iedereen heeft zijn plaats ingenomen volgens hun tickets. We hebben de eerste grens gepasseerd, wat in feite direct vastgesteld contact is tussen validators en blokcollators. In Ethereum en Polkadot zijn dit nu enigszins verschillende schema's. Maar alles wat aan het begin aan de linkerkant gebeurt, biedt geen cyberbeveiliging voor gegevens en berekeningen. Het is slechts voorbereiding. Zodra we de aandacht van de validators hebben getrokken en de omgeving zijn binnengegaan, begint het werk met het blok informatie in de wereldcomputer. Een willekeurig geselecteerde validator, in ons geval, met een busroute - een controller, gaat eigenlijk door elk van de stoelen, controleert het ticket, controleert en voert alle berekeningen uit die zijn gemaakt, verzamelt alle informatie in een boom. De resulterende wortelknoop van deze boom wordt de header van het voorgestelde blok. De validator die daadwerkelijk alle berekeningen met dit blok informatie uitvoert, communiceert met de andere deelnemers die een soortgelijke functie uitvoeren voor dezelfde route in een ongedefinieerd tijdsbestek. En terwijl we met hen communiceren en hen vragen om alle berekeningen te verifiëren, vullen we eigenlijk een bepaalde opslag van gegevens in het netwerk. Het is geen specifieke fysieke opslag; er is geen specifiek IP-adres, geen specifieke harde schijf waarop ze allemaal laden via een VPN of inlog- en wachtwoordschema, natuurlijk niet. In het proces van communicatie met andere validators blijven de gegevens op hun lokale machines, en deze gegevens zullen verder deelnemen aan de transformatie van deze kandidaat in een nieuw blok informatie. In wezen wordt het verzegelde blok dat zal worden afgewikkeld in de relay chain verzameld. We hebben een blok samengesteld. Alle metadata rond de berekeningen is al ingevuld, wat betekent dat we kunnen proberen om verder te gaan naar de volgende grens.\n\nOp dit moment gaan we dieper in op de passage van de volgende grens. Het meest cruciale aspect in de laatste fase wordt de blokkop. We maken ons minder zorgen over de uitvoering van berekeningen; we kunnen hier ons perspectief vereenvoudigen, aangezien berekeningen kunnen variëren op basis van de architectuur, of het nu Ethereum of Polkadot is. Het belangrijkste punt is dat, in de tussenfase, vanuit wat ik observeer in de theorie en praktijk van het implementeren van het concept van de wereldcomputer, de meeste berekeningen op een tussenliggend niveau plaatsvinden. Het laatste niveau blijft alleen over om essentiële controles uit te voeren. Bijna al deze controles in een multi-chain architectuur hebben betrekking op de concatenatie of samenvoeging van blokkoppen tot één blok.\n\n\nIn het laatste deel van onze reis wordt het belangrijkste element in het informatieblok van de wereldcomputer de hoeksteen - de kop. Het tweede component gaat meer over meta-informatie. Als de kop het daadwerkelijke resultaat is van alle berekeningen, bestaat de aanvullende meta-informatie die wordt verzonden uit ontvangstbewijzen en handtekeningen van de validators die hebben deelgenomen aan de tussenfase van dit proces. In de laatste fase kunnen we het geheel alleen visualiseren als de samenstelling van dezelfde boom, niet als een lijst van transacties. In het laatste deel van de relay chain is het cruciale aspect de samenstelling van koppen uit veel vergelijkbare processen, maar gekoppeld aan verschillende segmenten van de wereldcomputer, verschillende parachains.\n\nElke parachain, elke set van validators - we hebben één voorbeeld besproken, maar in werkelijkheid gebeuren dergelijke blokvoorbereidingen voor parachains 30-40 keer. Het aantal parachain-slots of het aantal L2-netwerken in Ethereum zal resulteren in een vergelijkbaar aantal processen met een vergelijkbare architectuur. Echter, in de laatste fase zullen we overal een ongeveer identiek beeld zien - hoe de blokkop zal worden gevormd uit een veelheid van koppen van andere blokken. In dit proces moeten we nog een entiteit introduceren en terug springen over de grens naar de tweede fase.\n\nFinalizers. In feite zijn ze ook validators, maar relay chain validators. In de Polkadot-architectuur hebben we duizend validators verdeeld in twee groepen. De eerste, een zeer kleine groep, is alleen verantwoordelijk voor het vormen van de blokkop en een nieuw blok bestaande uit de koppen van de State of the States-blokken. De tweede groep - parachain validators - is verder onderverdeeld in veel subgroepen, maar deze groep wordt parachain validators genoemd. In L2-netwerken boven Ethereum zal dit verhaal uiteindelijk meer begrip, meer noemers krijgen. Laten we ons nu richten op de Polkadot-architectuur. Finalizers, naast het controleren van een aanvullende set meta-informatie en het opnieuw controleren van een validator met een specifiek ID, willekeurig gekozen om dit blok van alle blokken te genereren, helpen ook bij het opnieuw controleren van meta-informatie, controleren en samenstellen van alle koppen tot één. Het is een beetje complex, ja, als we het bekijken vanuit het perspectief van de boomassemblage.\n\nNaast dit alles vindt in de Polkadot-architectuur en in Ethereum met de nieuwste wijzigingen een controle van gegevensbeschikbaarheid plaats. Hiervoor bezoeken finalizers parachain-validatoren en proberen ze daadwerkelijke informatie op te vragen over elk blok dat is opgeslagen in het netwerk. Als ze gegevens ontvangen van minstens 1/3 van de validators, met behulp van technologie die redundante opslag van informatie mogelijk maakt, en vervolgens, als iemand het verliest, kunnen één, twee of drie validators het nog steeds herstellen, is er een kritische drempel op 1/3. Als 1/3 van de knooppunten reageert en zegt dat we gegevens hebben over het geproduceerde blok, vertellen finalizers het blok dat het al een volledig gevormd informatieblok is, dat alle berekeningen correct zijn uitgevoerd, dat we al de kop van dit blok hebben genomen en gecombineerd met de koppen van iemand anders van andere segmenten van het netwerk. We hebben al de hoofdkop van het hele netwerk gevormd. Daarna plaatsen finalizers veel vinkjes op het definitieve blok, dat alle uitgevoerde berekeningen combineert.\n\nOp dit moment is dit de situatie vanuit het perspectief van het meest technisch geïmplementeerde multi-chain heterogene ecosysteem, dat Polkadot is. Het is het meest technisch geïmplementeerde multi-chain heterogene ecosysteem, niet al te ver van Ethereum. Ik zou me willen richten op de vergelijking, en als iemand geïnteresseerd is in het begrijpen van hoe informatieblokken stromen in Ethereum met L2-netwerken, kan je dat nu proberen. Ik zal terugkomen op deze vraag wanneer sommige elementen van Ethereum, op het gebied van heterogeniteit en multi-chain aspecten, zijn voltooid. Het kan 1-2 jaar duren, en dan kunnen we zo'n beeld opbouwen. Desalniettemin kunnen we over het algemeen een schema accepteren met drie hoofdfasen:\n\n**1. Vorming van een kandidaat voor het informatieblok:**\n   - In deze fase wordt de initiële kandidaat voor het informatieblok gevormd.\n\n\n**2. Uitvoering van alle berekeningen, gegevensopslag, gegevensbeschikbaarheid, hercontrole met andere knooppunten, ervoor zorgen dat alle toestandsovergangen correct worden uitgevoerd volgens specifieke algoritmen, en het opslaan van deze algoritmen in de hoofdcitadel:**\n   - In deze fase wordt de daadwerkelijke uitvoering van berekeningen, het opslaan van gegevens op bepaalde lagen, het waarborgen van gegevensbeschikbaarheid, hercontrole met andere knooppunten om te bevestigen dat alle toestandsovergangen in overeenstemming zijn met algoritmen die ergens in de hoofdcitadel zijn opgeslagen.\n\n\n**3. Finalisatie, waarbij de berekeningen niet opnieuw worden gecontroleerd, maar de meta-informatie zal verifiëren, hoe deze meta-informatie is opgeslagen. Vervolgens zal het het uiteindelijke blok assembleren, dat de toestand van de staten is, en het vrijgeven als een gemeenschappelijk informatieblok voor het gehele gesegmenteerde multi-chain netwerk:**\n   - De laatste fase omvat het controleren van de meta-informatie, het verifiëren van hoe deze meta-informatie is opgeslagen, het assembleren van het uiteindelijke blok (toestand van de staten) en het vrijgeven ervan als een gemeenschappelijk informatieblok voor het gehele gesegmenteerde multi-chain netwerk.\n\n\nOp dit punt kunnen we zeggen dat onze informatie is opgeslagen. Het is door het hart gegaan, het hart heeft zijn gegevensoverdracht correct uitgevoerd, en we kunnen al gebruik maken van de uitvoerwaarden. Sommigen zullen ze gebruiken om een slimme-contract-gekocht appartement te openen met een slim slot, terwijl anderen misschien pronken met hun NFT, zojuist ontvangen voor 10 ethers.\n\nOver het algemeen is dit ongeveer hoe het werkt. Hiermee wordt het theoretische deel afgesloten. Ik denk dat het ongeveer 2 uur duurde, en voor ons liggen praktijksessies die ik de komende maanden zal opnemen. Ze zullen ons helpen om de waargenomen gegevens vanuit het consolevenster, gedecentraliseerde toepassingen, block explorers te begrijpen, waar we geleidelijk zullen begrijpen hoe al deze theoretische cijfers en letters er eigenlijk uitzien in de implementatie met behulp van Polkadot als voorbeeld. Ik zal ook beginnen met praktische implementaties op het L2-niveau met behulp van een van de bekende frameworks voor het bouwen van L2. Bedankt aan iedereen die heeft gekeken.\n","fileInfo":{"path":"nl/learn/world-computer/the-path-of-a-new-block-of-information-in-the-world-computer.md","name":"the-path-of-a-new-block-of-information-in-the-world-computer"},"defaultName":"World computer in your home","lastUpdate":null}},"context":{}}