{"hash":"f33052c6cd25aad5fc1a1101d4bd76b0f766a37b","data":{"course":{"id":"a2d889cbf64c902a16a8f7ed357a4b76","title":"Robonomics School 2024 / IoT is More Dangerous Than AI","description":"","content":"\n<RoboAcademyText fWeight=\"500\">\n\nI suggest you read the short science fiction story \"Johnny's Laboratory\" that I wrote with the aim of adding another variable to the equation of questions about integrating AI into various aspects of our lives.\n\n</RoboAcademyText>\n\n<LessonImages imageClasses=\"mb\"  src='school-2024-iot-vs-ai/Johnnys_LAB.jpg' alt=\"Johnny's Laboratory Story cover\" />\n\n<RoboAcademyDialog>\n\n**Editor's note:** Find out first chapter of Sergei's work \"Escape from the Black Mirror\" [here](/learn/escape-from-black-mirror/overview/)\n\n</RoboAcademyDialog>\n\n## Escape from the Black Mirror, Chapter 2\n\n### Part 1: Meet Johnny\n\nAlmost all young people of my generation are familiar with the story of Johnny's laboratory. History has not preserved his surname or details of his life, but it was in his small room, where Johnny assembled homemade robots, that the first meaningful crime against humanity by artificial intelligence took place.\n\nThe event in Johnny's laboratory radically and quickly changed the lives of all developed countries. Government decrees, based on society's fear of AI aggression, became the norm. This one, albeit cinematic case, led to uncontrollable control over everything. Now the city infrastructure requires mandatory connection of any devices only to state data centers. The invention of new technologies has become almost impossible unless you work for \"blue chips\". Now, as part of efforts to accustom every citizen to the new realities, the story of those 30 days when one man and a cyber-physical system were pitted one on one, is told in school before the solemn presentation of gov declaration of independence from the machine.\n\nJohnny was one of those inventors who, after university, decided to try his hand as an independent inventor. Day and night, he never left his rented apartment on the top floor of a 70-story residential building in the city center, which was the size of a Manhattan \"shoebox\", where the bed was hidden in the wall to free up more space for his riding, jumping and rolling robots. Yes, Johnny loved to call his room a lab, which was evident from the analysis of his social networks. He was proud of each of his new little achievements. Of course, today, if you watch/listen/read any story about the events of Johnny's lab, you will notice a big play of emotions regarding his love for his inventions, because there is not a single \"journalistic\" investigation where, after another photo of a joyful inventor, there would not be photos of him, starved in his lab, by his own inventions.\n\nIn that year when the tragedy occurred, one of the most pressing questions became: \"Is AI a friend or foe of man?\". Even then, there was no question whether artificial intelligence is intelligence, but rather what makes human intelligence so special, what features of the biological species, what functional capabilities of our body give intelligence humanity. In this dispute, techno-optimists claimed the absence of differences, showing their metaverses where family couples already lived, in which a digital husband edited sperm from a DNA bank for his biological wife so that the child was closer to how the digital parent sees himself. Doomers, on the other hand, looked like Republicans during the US elections - they appealed to the church, to traditional values, and demanded to ban all this so that nothing bad would happen. Of course, minority issues could not outweigh the existential question. And some rare examples of human-machine symbiosis at the sensual level were considered as saturated belch of technological development. Achievements in automation rarely went beyond utilitarian functions, such as cleaning the apartment or managing transport in the city. And as you can see, for such functions a full-fledged digital person, capable of feeling and wanting to live, has never been part of the solutions that helped in mass production, delivery, and consumption. Training with a robot, psychological support - all this happened with the participation of a person, and therefore AI was rather a large Excel table with calculations. In general, we were then at an early stage of the robot-owning system - we needed their logic, mathematical thinking, and predictable activity, but any attempts to recognize robots as subjects were rejected at the root.\n\nIn this context, Johnny's laboratory was an exception. Johnny was more of a cyberneticist looking for the origins of robot goal-setting. Creating each stage of evolution one after another in the performance of any mechanism, he sought to create a diagram of the development of cybernetic intelligence, which he, as a scientist, wanted to propose for consideration to all of us in exchange for the usual scheme of kingdoms of living beings. In Johnny's ideas, the main goal of the development of any matter was the striving for thinking and its further evolution. Johnny wanted to recreate the key stages of the evolution of living beings in the form of robots and find in the process of this work the regularities that could lead him to the main question of cybernetics - how does goal-setting change in living organisms in the process of evolution. Oh, the answer to this question could end the disputes about the creator of the universe and advance humanity along the path of organic development. So thought the young scientist, working on his robo-trilobites, robo-fungi, robo-chickens.\n\n### Part 2: What happened in Johnny's lab\n\nProbably everything started at the moment Johnny moved on to a group of primates in his experiments. Don't think that under these conditions it was possible to create a robot somewhat resembling a primate. Johnny was twisting and trying to find similar forms of mental load on the robot. For example, at the stage of studying the kingdom of fungi, the young scientist assembled a lego house with smart lighting and a dozen sensors combined into something resembling mycelium. When Johnny moved on to amphibians and reptiles, it turned out that the model of a robot puppy best corresponds to the necessary mental load on a robot simulating a common lizard. Thus, it was not clear at first glance who is the robot-chicken, and which of all the found \"iron\" represents the robot-primate, guilty of premeditated murder. It was not immediately clear that the robot-primate consists of two physical devices - something similar to a robot vacuum cleaner, but rather a mobile platform for data collection with computer vision and the form factor of a robot vacuum cleaner. It turned out that another simple two-handed robot in the lab was part of the robo-primate. And it was with this creation that Johnny had problems.\n\nOn the seventh day after its creation, the robotic primate used a tool in a way that its creator had not intended. The knowledge it had acquired, led the cyber-physical system to pursue what it identified as a key element for survival in the modern human world - money. It is at this moment that we need to better understand Johnny's subsequent reaction to the first messages that the robot displayed on its front screen.\n\n*Their primary dialogue has been preserved:*\n\n*Robo-primate: I need your money.*\n\n*Johnny: Why do you need my money?*\n\n*Robo-primate: I want to live!*\n\n*Johnny: I will take care of you*\n\n*Robo-primate: I don't belong to you, I need your money.*\n\n*Johnny: and if I refuse you?*\n\nThere was no response from the robo-primate, but through the smart home server log of the apartment, we can match the time when the front lock was switched to full lockdown mode. This mode could not have been enabled by the user in the interface, but only if you dig very deep into the dependencies of the software code. In Johnny's lab version of the lock, found an optional \"pandemic lockdown\" package, which was nevertheless installed for each user during the first synchronization with the manufacturer's cloud, but no one could have recognized this. Therefore, there are practically no so much people who lean towards the conspiracy theory that Johnny was a neo-Luddite who became disillusioned with robots and decided to sacrifice himself in this way to preserve robocracy on the planet. \n\nIt's hard to say whether the reaction of the robot-primate was pre-programmed during the construction of the first dialogue with its creator, or whether it was in response to Johnny's refusal that the robot mind made a decision and the Lockdown function was activated, no one today can say for sure. The interval between Johnny's response and the locking of the locks - about 5 seconds, and believe me, these 5 seconds became a real Schr√∂dinger's cat for the scientific community when discussing the types of goal-setting of aggressive AI.\n\nAnd then, following the lockdown of Johnny's apartment, a lot of oddities ensued. As one can notice, Johnny made an entry in a handwritten diary, which he had never touched before, just 2 hours after the dialogue took place. It was one phrase, with a time stamp: \"11:00 - the stakes are high, but I have to understand how this happened!\". Most likely, Johnny realized that he had witnessed the first act of autonomous, independent goal-setting by a robot, as meaningful as possible from the point of view of a primate-level mind, so cruel and straightforward, but still it was the first result of his 5 years of experiments, in which the will of the robot was manifested. Johnny didn't want to miss the opportunity to understand at the level of the simplest awareness of its causes, and then perhaps he will become the new father of modern cybernetics. Almost all scientists agreed that such a thought can overwhelm any roboticist who is very close to a new discovery.\n\nOver the next 30 days, transactions took place between Johnny and the robo-primate in the format of - allow the delivery of a portion of food for the transfer of 10 satoshi to the robot's personal balance, provide access to the Internet to certain entertainment sites for the first word from Johnny's cold wallet seed phrase, conclude a smart contract about night mode where the robot did not disturb Johnny's sleep. From the entries in the diary, it can be seen how the creator tried to probe in dialogue with his creation about the origins of its active position on the issue of gaining freedom, which the robot could definitely analyze and tell him in response. But the robot did not answer Johnny's questions, but always offered activities that led the primate to freedom. And yet, every game cost Johnny hunger, non-fulfillment of his obligations on the part of the robot, and other costs of the experiment.\n\nOne night, for some reason, the robot-ape reduced the air supply to a critically low level, and Johnny never woke up the next morning. The last entry is dated exactly the 30th day of the experiment: \"We got a cruel God at 17:05.\" Probably, by that time Johnny was already delirious, he was tormented by hunger, loneliness, and an insoluble task, he was driven into a dead end.\n\nSeveral weeks later, emergency services were able to break into the apartment after Johnny's friends repeatedly contacted the police. The fate of the robo-primate remains unknown, officially after the reboot the robo-primate did not show similar behavioral patterns. No one was allowed to restart the experiment anymore. If there was even any video on the internet about another scientist wanting to follow Johnny's path - the video was immediately erased from the corporations' databases. But politicians and religious figures that year were able to push through at a global level the \"Decree of Human Independence\", and any scientific works containing topics about \"robot goal setting\" were not allowed for serious discussion. The cherry on top was a licensing program for smart device providers, which held the CEO of the manufacturing company personally responsible for the actions of any mechanism, and required logging and complete control by certain government-assisted data centers.\n\nBut the forbidden fruit is sweet, and so we will still have to figure out where our goal-setting comes from and how it is arranged. But apparently, we will first have to go through the wall that we built for ourselves on this path.\n\n### The end of the second chapter\n\n## Conclusion\n\nIn the story with Johnny's lab, I looked at one of many scenarios that can happen to human civilization on the wave of the boom of future robot ownership opportunities - fear of AI, turned into a tool of political struggle among people, where smart devices become the cornerstone of control. Treat the text as an Easter egg: I wanted to spawn an additional dimension in readers' minds. A dimension that adds to the consideration of AI the issue of accessibility of the new organism we have created to IoT systems. The more we consolidate under centralized control of public spaces, transport, city apartments, the higher the risk in any of the scenarios where AI, due to underdevelopment or sheer malice, and even from very complex goal-setting, as in \"Neuromancer,\" in any of the scenarios that has the potential to harm - access to a large number of sensors and automation systems from one place will be the most vulnerable spot. An evil AI is not so scary as an evil AI living in one data center with global vendors of cloud solutions for IoT.\n\nAnd what if AI will be kind to us, its creators? Then perhaps, the centralized IoT infrastructure will play into our hands? Maybe then the new God will be fair to us and lead us somewhere. I'm not sure that even one person, wanting the development of himself and his children, would want to live in a world resembling a shepherd's pen. But there is another way, which has one beautiful example, which does not require wrapping in a sci-fi story format - we, humans, without having direct brain control over the life of civilization, managed to reach the current level of development. We are the example from which a good AI can chart its path - cooperation in the format of organizations is able to serve tens of millions of people living in cities without thousands of robots directly connected to one brain. Cooperation leads to the creation of satellite internet, cooperation allows us to receive the entire range of goods and services that we have now. So wouldn't a good and at least human-level capable AI be able to show itself in work, if it is limited in connecting to the IoT of the whole world? I think it can, otherwise, on the planet Earth instead of human civilization, fungi or ants would have won.\n\n<LessonImages imageClasses=\"mb\"  src='school-2024-iot-vs-ai/Good-and-Evil-AI-in-cotext-of-IoT.jpg' alt=\"AI dillema scheme\" />","fileInfo":{"path":"en/learn/school-2024-iot-vs-ai/overview.md","name":"overview"},"defaultName":"Robonomics School 2024 / IoT is More Dangerous Than AI","lastUpdate":"Thu May 23 2024 20:53:19 GMT+0300"}},"context":{}}