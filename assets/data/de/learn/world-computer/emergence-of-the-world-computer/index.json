{"hash":"5d4f08f99729279cbad41c23c8d66dce511a8ae5","data":{"course":{"id":"acb8e72fddbf967d710dd2858e9fd845","title":"Teil 3: Entstehung des Weltcomputers","description":"Im dritten Teil mit dem Titel \"Entstehung des Weltcomputers\" werden wir versuchen, Schicht für Schicht die technische Umsetzung des Weltcomputers mithilfe von Beispielen aus Ethereum und Polkadot nachzubilden, wie zuvor.","content":"\nIm dritten Teil mit dem Titel \"Entstehung des Weltcomputers\" werden wir versuchen, Schicht für Schicht die technische Umsetzung des Weltcomputers mithilfe von Beispielen aus Ethereum und Polkadot nachzubilden, wie zuvor.\n\nLassen Sie uns mit Ethereum beginnen. Ethereum begann 2015 mit einem Zustand, der als Kombination des Proof-of-Work-Konsensalgorithmus charakterisiert werden kann, der es dem Weltcomputer ermöglichte, in einem dezentralen Zustand zu existieren (wie in Teil 2 diskutiert). Darüber hinaus wurde die Ethereum Virtual Machine (EVM) eingeführt, die als Turing-vollständige Rechenmaschine diente. Zusammen bildeten diese beiden Elemente die erste Version des Weltcomputers, manchmal als Vorläufer bezeichnet. Im Rahmen dieser Kontextualisierung begannen dezentrale Anwendungen oder Smart Contracts aufzutauchen.\n\nIn den nächsten 5 Jahren führte Ethereum ein relativ unverändertes Leben, unterzog sich einigen technischen Feinabstimmungen, wie einer kontinuierlichen Erhöhung der Gasgrenzen, mit Ausnahme von Ereignissen wie der Shanghai-Fork. Besonders während des zweiten DEFCON in Shanghai wurde ein Denial-of-Service-Angriff ausgeführt, der eine Funktion in der virtuellen Maschine ausnutzte, die minimalen Gas verbrauchte, aber signifikante Berechnungen im Ethereum-Netzwerk auslöste. Dies führte zu einem Speicherüberlauf, der effektiv einen gesamten Ethereum-Knoten störte. Dieser Vorfall verdeutlicht die komplexen Details, die bei der Arbeit mit einer großen und abstrakten Lösung wie der Erstellung einer virtuellen Maschine auftreten.\n\nIn der Folge kam es gegen Ende des Jahrzehnts, insbesondere 2020, zu einem bedeutenden Wandel, mit dem Aufkommen von Ethereum 2.0. Allerdings wurde Ethereum 2.0 mittlerweile veraltet, und ich würde den eigentlichen Durchbruch als Beginn um 2019-2020 charakterisieren. Während dieser Zeit gab es einen echten technologischen Durchbruch in Ethereum, der sich auf das Konzept von Ethereum 2.0 zubewegte. Der Moment des technischen Wandels in der Architektur von Ethereum kann als das Ereignis betrachtet werden, das als \"die Fusion\" bekannt ist, bei der die Funktionalitäten der Beacon Chain kombiniert wurden. Die Fusion markierte einen signifikanten Paradigmenwechsel in Ethereum, der es in einen etwas anderen Zustand versetzte als zuvor. Der tatsächliche technische Wandel in der Architektur von Ethereum kann mit \"der Fusion\" in Verbindung gebracht werden, bei der die Funktionalitäten der Beacon Chain integriert wurden. Für eine detaillierte Geschichte dazu können Sie die Website ethereum.org konsultieren, die einen ausgezeichneten Artikel über das Nebeneinander des traditionellen Ethereum-Blockchains mit dem 2015 gestarteten parallelen Blockchain und der Ethereum Virtual Machine bietet.\n\nAls der Merge stattfand, beobachteten wir eine neue architektonische Darstellung, sowohl auf Netzwerkebene als auch für einzelne Knoten, die mit dem Ethereum-Netzwerk interagieren. Was war die tatsächliche Veränderung? Für viele bedeutet der Merge den Übergang von Proof-of-Work zu Proof-of-Stake, was tatsächlich signifikant ist. Es impliziert eine erhöhte Effizienz und Feinabstimmung, aber es handelt sich immer noch um eine Abstimmung im Verhältnis zu einem der Parameter. Die bemerkenswertere interne technische Änderung für jeden Netzwerkclient war jedoch die Aufteilung. Es gab nicht mehr einen spezifischen Netzwerkclient oder eine monolithische Architektur. Stattdessen erhielten wir zwei Komponenten eines einzelnen Knotens, die mit dem Ethereum-Netzwerk interagieren.\n\nDer erste Teil, den ich auf dem Diagramm als \"Beacon Chain\" bezeichnet habe, repräsentiert im Wesentlichen ein kollektives Bild aller Innovationen, die zum Zeitpunkt des Merges in den Ethereum-Client eingeflossen sind. Der zweite Teil ist die erhaltene virtuelle Maschine. Dennoch lohnt es sich auch hier etwas hinzuzufügen. Es begannen tatsächlich Diskussionen über die Ersetzung der virtuellen Maschine, die ausschließlich darauf ausgelegt war, mit Smart Contracts und Smart Contracts in einer bestimmten Sprache - Solidity - zu arbeiten. Dies liegt daran, dass es bis 2015 praktisch keine Interpreter mehr für Smart Contracts in anderen Sprachen als Solidity gab und die Architektur aus der Sicht eines Ethereum-Programmierers etwas einseitig erschien. Man lernt ein Schnipsel JavaScript in Form von Solidity, schreibt darauf Smart Contract-Code und erhält seine DApp, wie zum Beispiel Uniswap.\n\nSeit dem Aufkommen einer komplexeren Ethereum-Architektur drehen sich die Diskussionen um die Idee, dass die virtuelle Maschine, die seit 2015 als etwas monolithisches Element existierte, auch in der neuen Architektur ersetzt werden kann. Die Diskussion verlagerte sich dahingehend, sie durch etwas wie WebAssembly (Wasm) oder eine interessantere Lösung aus der Perspektive des Schreibens von Code für den Weltcomputer zu ersetzen. Man könnte sagen, \"Wasm mit einem Fragezeichen.\"\n\nAus der Perspektive der Beacon Chain arbeitet sie tatsächlich nach dem Proof-of-Stake-Prinzip, aber noch interessanter ist die Einbeziehung von Gasper. Dies stellt eine Modifikation der ursprünglichen Ideen zu Casper dar. Casper, oft als freundlicher Geist-Finalitätsmechanismus bezeichnet, wurde möglicherweise bereits bei Defcon 3 oder 4 eingeführt und vielleicht sogar bei Defcon 2 diskutiert - ich erinnere mich nicht genau. Aber auf der EthCC-Konferenz in Paris, die definitiv 2018 stattfand, diskutierten Vlad Zamfir und Vitalik aus verschiedenen Räumen heraus über das Aufkommen von Casper als freundlicher Geist, der die Teilnehmer im Proof-of-Stake überwacht und dem Netzwerk zu Hilfe kommt, wenn ein Knoten sich falsch verhält. Aus dieser Idee von Casper entsteht Gasper. Ohne zu sehr in die Terminologie einzutauchen, erfährt der Konsensalgorithmus eine Verschiebung, ändert sich nicht nur in Bezug auf Einfachheit, sondern wird auch komplexer, ähnlich wie bei Polkadot. Wie ich bereits erwähnte, hat Polkadot zwei Konsensalgorithmen, Babe und Grandpa. Ähnlich verhält es sich mit der Beacon Chain-Funktionalität von Ethereum, bei der die Erreichung von Konsens und Finalität nicht so unmittelbar ist. Es beinhaltet Epochen, und das Netzwerk arbeitet in einem komplexeren Szenario, erreicht einen Zustand, der bereits etwas dynamisch ist, nicht eingefroren und im Wesentlichen in Stein gemeißelt.\n\nWas kann im Zusammenhang mit 2024 hinzugefügt werden? Für mich war es eine langwierige Beobachtung und ein Versuch zu verstehen, ob Ethereum letztendlich Sharding implementieren würde oder nicht. Sharding ist die Fähigkeit, nicht nur mit einer einzelnen Blockchain, sondern mit mehreren Blockchains innerhalb eines Netzwerks zu existieren. Als ich den Merge und den gleichzeitigen Aufstieg von Layer 2 (L2)-Netzwerken beobachtete, kamen mir Fragen in den Sinn, ob Sharding tatsächlich realisiert werden würde. Sharding schien mir aufgrund seiner Homogenität interessant zu sein - mit mehreren Ketten, die fast identisch sind und keine spezifischen Merkmale aufweisen. Es schien mir ein interessanter Ansatz zu sein, aber nicht so flexibel wie ein heterogener Ansatz. In L2-Netzwerken konnte ich bereits vor einigen Jahren die Heterogenität von Ethereum erkennen, seine Fähigkeit, mit verschiedenen Arten von spezifischeren Blockchains zu arbeiten. Ich war neugierig, in welche Richtung es gehen würde - ob Sharding mit seiner Homogenität die L2-Lösungen verdrängen würde oder ob die L2-Lösungen mit einem heterogenen Ansatz die Beacon Chain und die Hauptknoten des Ethereum-Netzwerks saturieren würden.\n\nHeute, im Jahr 2024, basierend auf Artikeln auf ethereum.org, scheint es, dass Sharding als Konzept zurückgestellt wurde und der Fokus darauf liegt, verschiedenen L2-Netzwerken zu helfen, sich mit der Beacon Chain zu integrieren und sich mit der Funktionalität der Hauptkette abzustimmen, die jetzt in zwei Elemente in der Architektur des Ethereum-Netzwerks aufgeteilt ist.\n\nDaher, ohne in die Details einzutauchen, wie L2-Netzwerke strukturiert sind - obwohl wir darauf eingehen werden, wenn wir den zweiten Teil des Boards ausfüllen - sollten wir uns vorstellen, dass Ethereum jetzt eine Art Beacon Chain ist, ein Leitstern für zahlreiche L2-Netzwerke. Diese L2-Netzwerke können spezifischere Funktionalitäten haben, ihre Logik gemäß einer Reihe von individuellen Funktionen ausführen. Dies steht ein wenig im Einklang mit der Idee eines Schweizer Taschenmessers - Ethereum wird nicht zu einem Schweizer Taschenmesser, aber L2-Netzwerke beginnen sich in ihrer Architektur zu unterscheiden. Sie duplizieren die Funktionalität der abstrakten Rechenmaschine von Ethereum, führen sie jedoch mit geringeren Gasgebühren oder innerhalb ihres spezifischen Segments aus. Einige denken bereits darüber nach, ihre L2-Schicht zu optimieren und effizienter zu gestalten, indem sie sich auf spezifische funktionale Fähigkeiten konzentrieren. Meiner Meinung nach erleben wir also das Aufkommen von Heterogenität in dem Weltcomputer, der homogen sein sollte. Es ist auch wichtig, nicht zu vergessen, dass dezentrale Anwendungen (dApps) immer noch innerhalb der Hauptblockchain existieren, innerhalb derselben Blockchain, die 2015 begann. Dies bedeutet, dass während des Mergers, während des Übergangs zum neuen architektonischen Zustand, keine Löschung, kein Löschen der vorherigen Geschichte stattfand. Alle dezentralen Anwendungen und Smart Contracts, die diesen Anwendungen zugrunde liegen, existierten weiterhin und existieren auch heute und wahrscheinlich morgen. Dies ist eine Frage, die wir am Beispiel von Polkadot untersuchen werden, aber es besteht immer noch das Gefühl, dass es möglich sein wird, eine dezentrale Anwendung in der Beacon Chain - dApps - abzuwickeln.\n\nZusammenfassend betrachten wir die technische Umsetzung des heutigen Ethereum als Weltcomputer. Jeder Netzwerkknoten besteht aus zwei Teilen. Die erste Schicht ist für die Ethereum Virtual Machine (EVM) verantwortlich, die tatsächliche Funktionalität der virtuellen Maschine oder Turing-vollständigen Maschine, wenn wir in theoretischen Begriffen sprechen. Möglicherweise werden wir das Aufkommen von Alternativen zur virtuellen Maschine sehen, die 2015 entworfen wurde. Diese Alternativen werden wahrscheinlich in Bezug auf abstraktere Programmiermöglichkeiten als das Schreiben von Smart Contracts in Solidity übertreffen. In der Zwischenzeit fühlen sich Smart Contracts in Solidity weiterhin wohl. Wenn Sie Funktionalitäten für die Ethereum-Hauptkette schreiben möchten, ohne eine Infrastruktur über Ethereum zu erstellen, ohne Berechnungen auszulagern, um sie günstiger zu machen usw., können dezentrale Anwendungen, die Sie als Smart Contracts schreiben können, immer noch in der Hauptblockchain von Ethereum untergebracht werden. Gleichzeitig ist die Funktionalität der Beacon Chain entstanden, die die Konsenslogik zwischen Validatoren vom Hauptprotokoll der Rechenmaschine trennt. Dies ermöglicht zusätzliche Flexibilität in Bezug darauf, wie der Konsens funktionieren sollte und wie er weiter modifiziert werden sollte, ohne die virtuelle Maschine selbst zu beeinträchtigen. Das Beispiel von Shanghai und Defcon 2, bei dem ein kleiner Opcode-Fehler zu einem Ausfall eines Teils der Infrastruktur führte, deutet darauf hin, dass es gut wäre, solche komplexen Funktionalitäten in zwei Teile aufzuteilen.\n\nWas ist interessant an der Beacon Chain? Es handelt sich um einen komplexeren, umfassenderen Algorithmus zur Erreichung von Netzwerksynchronizität und Finalisierung mit der Einführung von Konzepten wie \"Epoch\" und dem Vorhandensein eines Geistes, der im Netzwerk lebt.\n\nSchließlich ist es jetzt wichtig zu bedenken, dass Ethereum effektiv der Homogenität ein Ende setzt, der Idee, hundert identische Blockchains mit derselben virtuellen Maschine arbeiten zu lassen, in der Smart Contracts in Solidity geschrieben werden können. Stattdessen schlagen verschiedene Projekte ihre eigenen Architekturen oder dieselbe virtuelle Maschine vor, die über die Grenzen der Hauptblockchain hinausgeht. Alternativ versuchen sie, ihre spezifischere Anwendung zu erstellen, die auf der Hauptkette der Beacon Chain als in Solidity geschriebener Smart Contract fungiert. Dies ist die aktuelle Darstellung von Ethereum, das nicht zu Ethereum 2.0 wurde. Es bleibt dasselbe Ethereum - ein Projekt, das einst mit Proof of Work + Turing-vollständiger Maschine begann und sich in diese Architektur verwandelte.\n\nNun wollen wir uns ansehen, wie Polkadot in den letzten 5 Jahren entstanden und entwickelt hat. Polkadot entstand fünf Jahre nach Ethereum, hervorgegangen aus dem Team, das einen der besten Clients für Ethereum entwickelt hat - Parity. Viele erinnern sich vielleicht an ihren Webclient, der im Vergleich zu Geth und anderen Implementierungen wahrscheinlich viel angenehmer zu bedienen war, zumindest aus persönlicher Erfahrung und der Erfahrung von Kollegen.\n\nZweitens war Polkadot meiner Meinung nach eine Erweiterung von Ideen, die Gavin Wood in die Entwicklung von Ethereum einfließen lassen wollte. Folglich könnte man sagen, dass sich Ethereum irgendwann in zwei Konzepte gespalten hat.\nWas hatten wir zum Zeitpunkt der Einführung von Polkadot? Die Relaiskette wurde gestartet. Interessanterweise, oder? Beacon-Kette und Relaiskette. Was stellte die Relaiskette dar? Anfangs gab es keine Möglichkeit, dort eine dezentrale Anwendung zu platzieren, einen Smart Contract dafür zu schreiben oder Ihren Code in WASM oder Solidity hochzuladen. Nichts davon war zum Zeitpunkt des ersten Blocks oder in den ersten Tagen des Bestehens der Polkadot-Relay-Kette verfügbar. Es gab keine Möglichkeit, Ihre Laufzeit hinzuzufügen, worüber wir gleich sprechen werden, und sie basierte nicht auf einem Proof of Stake; Stattdessen wurde ein Autoritätsnachweis verwendet. Dies ermöglichte es bestimmten von Polkadot-Entwicklern gestarteten Knoten, die ersten Monate oder Wochen zu überleben, während Angriffe auf die Kette gestartet werden konnten oder sich falsch verhielten. Dies wurde jedoch schnell geändert und die Relay-Kette wurde auf Proof of Stake umgestellt.\n\nAm Ende, nach ein paar Monaten des Bestehens der Relay Chain ohne dezentrale Anwendungsfunktionalität, ohne die Möglichkeit, Ihre Parachain oder L2-Netzwerk zu verbinden, ohne Benutzerfähigkeiten, wechselte das Netzwerk von einem Autoritätszustand zu einem Proof-of-Stake-Zustand. Dies gab Entwicklern die Möglichkeit, ihre Laufzeiten hochzuladen.\n\nAn diesem Punkt ist es auch interessant, die Unterschiede zwischen dem heutigen Ethereum und der Struktur des zentralen Teils von Polkadot zu diskutieren. Aus der Perspektive des Herzens, über das wir bereits gesprochen haben, wird das Bild nicht nur für Ethereum und Polkadot, sondern für jedes Projekt, das als abstrakte Rechenmaschine präsentiert werden möchte, absolut gleich sein. Aus ingenieurtechnischer und architektonischer Sicht ist es jedoch faszinierend, Beacon Chain & Relay Chain zu beobachten. Hier haben wir eine virtuelle Maschine, die seit 2015 vererbt wurde, aber es werden Alternativen vorgeschlagen. In der Relay Chain besteht die Möglichkeit, Ihre Laufzeit hochzuladen. Die Laufzeit ist in der Tat Ihre virtuelle Maschine. Zum Beispiel emulieren einige Parachains vollständig die Ethereum Virtual Machine. Es wird als Laufzeit geschrieben, was bedeutet, dass Sie im Grunde genommen eine Ethereum Virtual Machine-Analogie auf die Parachain-Ebene in Polkadot hochladen oder spezifischere Logik schreiben können, die mit vier oder fünf Funktionen funktioniert. Erinnern Sie sich an Teil eins über die Ideen - Sie können Ihr Schweizer Taschenmesser schreiben, aber es erfordert nicht die Erstellung der gesamten Infrastruktur. Sie können spezifische Funktionalitäten mit bestimmten Funktionen auf der Laufzeitebene implementieren, sie in die Polkadot-Relay-Chain einfügen und die Unveränderlichkeit dieser Laufzeit wird von den Polkadot-Validatoren sichergestellt.\n\nWas passiert als nächstes? Im Laufe von etwa einem Jahr beginnt sich eine Schicht von Parachains um die Relay Chain zu bilden. In Bezug auf die Ethereum-Implementierung könnte man sagen, dass L2-Netzwerke ziemlich ähnlich zu Parachains sind. Es gibt jedoch eine interessante Quer-Netzwerk-Unterscheidung, die ich faszinierend finde in Polkadot, und ich versuche weiter zu verstehen, wie sie sich entwickeln wird - nämlich die zweite Schicht der Validierung und Datenverfügbarkeitsprüfungen. Nach ein paar Jahren nimmt Polkadot eine Form wie diese an. Es ist nicht nur eine Relay Chain, in der Proof-of-Stake-Validatoren die Laufzeit zukünftiger Parachains schützen; eine zusätzliche und entscheidende Schicht der Datenvalidierung und Verfügbarkeitsprüfung entsteht aus Parachains.\n\nWenn Sie sich dieses Diagramm ansehen, versuchen Sie die Analogien zu bemerken, die entstehen, und die Unterschiede in den technischen Implementierungsdetails. Also, was repräsentiert das und wie vergleicht sich dieses Schema mit Ethereum? Wir haben ein L2-Projekt, in diesem Fall mit Polkadot, ist es eine Parachain. Eine Parachain generiert auch Informationsblöcke, die dann zur Relay Chain gehen, um kombiniert zu werden und einen Relay Chain-Block freizugeben als die Summe aller Header, Header und mehr Header. Die Parachain sammelt Transaktionen in einem Block mit Hilfe von Collators, die nicht an der Validierung beteiligt sind. Sie setzen nichts in die Relay Chain ein; sie verwenden nur die Laufzeit, die sich in der Relay Chain befindet. Sie holen sie ab, wenden sie auf Transaktionen an, führen notwendige Zustandsübergänge durch, bilden einen Block und, entscheidend, liefern einen Beweis für die Gültigkeit - einen Stempel, der kryptografische Beweise enthält, dass der Collator den Block korrekt zusammengestellt hat. Diese Informationen gehen an den externen Validierungsring der Relay Chain. In diesem Ring gibt es interne Validatoren von Polkadot - Parachain-Collators. Auch sie setzen nichts direkt aus der Sicht der Relay Chain ein. Parachain-Implementierungen führen manchmal ihren Konsens unter den Collators ein, und manche nicht. Zum Beispiel finden wir in Robonomics, bei der Implementierung einer Parachain, dieses Paradigma interessanter, weniger belastend und es macht das Netzwerk einfacher, bleibt aber funktional wesentlich. Jeder Collator, ohne mit jemandem Konsens zu erreichen - von uns verifiziert - kann einen Block vorschlagen und einen Beweis an die externe Schicht senden. Genau deshalb werden Blöcke vorgeschlagen, Beweise für die Gültigkeit der Blockzusammenstellung angeboten und es gibt einen externen Ring. Wir benötigen keinen Konsens von Parachain-Validatoren. Jeder kann einen Block generieren und senden, und wenn dieser Knoten des Collators falsche Informationen an die Parachain-Validatoren im externen Ring sendet, wird der Validator auf dieser Ebene es ablehnen. Es wird nicht in den zentralen Teil gelangen. Aber sagen wir, der Block wurde korrekt vom Collator bereitgestellt. Unsere Transaktionen sind drin; der Collator hat sie berechnet, die Laufzeit angewendet, die in der Relay Chain gespeichert ist, alle Zustandsübergänge ausgeführt, einen Beweis für die Gültigkeit gesammelt - die Gültigkeit des zusammengestellten Blocks - und ihn an den externen Ring der Relay Chain weitergeleitet. Hier, in jeder Epoche, die auch Teil der Finalisierung ist, haben jede Epoche Validatoren aus der Relay Chain, die in Parachains abweichen. Einige von ihnen bleiben in der Mitte, und die anderen gehen zu Parachains. Ihre Anzahl reicht von 16 bis 64 Validatoren, und diese Zahl, glaube ich, wird sich in der Spezifikation ändern - an manchen Stellen mehr, an anderen weniger. Parachain-Validatoren überprüfen die Informationen aus einer ausgewählten Gruppe von Validatoren erneut, ob alles vom Collator kommende korrekt ist, ob die Arbeit gemäß der Laufzeit durchgeführt wurde und ob der Beweis für die Gültigkeit tatsächlich gültig ist. Das ausgewählte Segment der Relay Chain-Validatoren, die bereits etwas gesetzt haben, antworten oder besser gesagt, zwitschern untereinander. Sie antworten dem ausgewählten Hauptblockproduzenten der Parachain, sozusagen, und sagen, \"Ja, wir stimmen zu. Es gibt keine Probleme. Sie können es durch den gesamten externen Ring innen tragen.\"\n\nUnd so gelangt fast alle Informationen, die auf den Parachain-Kollatoren gebildet wurden, mit Überprüfung im externen Ring, in den internen Ring. Der untere Teil, nicht dass er physisch unten ist, bildet immer noch den externen Ring - Datenverfügbarkeit. Daten beginnen in diesem Stadium überprüft zu werden, was bedeutet, dass im externen Ring nicht nur die Korrektheit der Blockmontage überprüft wird, sondern auch der Prozess der Vorbereitung auf die Verteilung innerhalb des Polkadot-Netzwerks beginnt, um sicherzustellen, dass die Blockinformationen in Zukunft nicht verloren gehen. Hier ist genau das, was ich im zweiten Teil über Chunks erwähnt habe, wie CD RW. In diesem Stadium der Blockvorbereitung für die Übertragung in den internen Ring wird die Datensicherheitsschicht als Dienst gebildet, etwas, das derzeit auch von einigen Projekten in Ethereum versucht wird. Einige Projekte fügen zusätzliche redundante Informationen direkt in Smart Contracts ein, die für die Überprüfung dessen erforderlich sind, was auf der L2-Ebene passiert, und gegebenenfalls das Slashing oder Bestrafen derjenigen, die es falsch gemacht haben. Es ist unmöglich, den externen Ring zu überwinden, ohne Blockinformationen zu verteilen und ohne Dutzende von Knoten mit Einsätzen erneut zu überprüfen, die auf der Annahme beruhen, dass die Laufzeit korrekt funktionieren muss.\n\nDaher ist die Information, die den externen Ring passiert hat, bereits ziemlich vertrauenswürdig, wahrscheinlich ja, man kann das sagen, und im internen Ring wird hauptsächlich nicht mit Parachain-Blöcken gearbeitet, sondern ihre Blockheader werden zu einem großen Header zusammengefasst. Das heißt, aus vielen Headern wird ein Header eines Relay-Chain-Blocks zusammengebaut - ein Mechanismus des Verknüpfens in Shared Security, wie in Polkadot erwähnt, der die Sicherheit von Parachains gewährleistet. Man könnte sagen, dass Parachains validiert werden und einen Zustand erreichen, in dem der Service in einer verteilten dezentralen Form im externen Ring existiert. Im internen Ring versucht die eingetretene Information, sich in einem Hyperblock zusammenzufügen, der alles genau verknüpfen sollte. Es finden keine Berechnungen statt; es gibt keine Neuberechnung von absolut allem. Die Montage des endgültigen Blocks findet sozusagen in der aktuellen Iteration des Weltcomputers statt, um die Frage zu klären, ob die Transaktion in einem bestimmten Parachain stattgefunden hat. Wir müssen einen Hyperblock zusammenstellen, der nicht alle Informationen aus den Parachains enthält, sondern alle auf dem externen Ring der Parachains überprüften Header in einen großen Block zusammenführt. Und so funktioniert unser Weltcomputer in Polkadot.\n\nLassen Sie uns diese beiden Schemata noch einmal gemeinsam betrachten: Relay-Kette, Beacon-Kette, Laufzeit, abgesichert durch Proof of Stake, bei dem jemand seine Mittel einsetzt, um zu validieren, dass sie ihre Arbeit immer korrekt ausführen werden. Es gibt eine virtuelle Maschine, in der Sie auch Ihre Mittel einsetzen können, und wenn Sie eine Berechnung oder einen Zustandsübergang durchführen, der nicht mit der Spezifikation der Ethereum Virtual Machine übereinstimmt, werden Sie bestraft.\n\nBei Polkadot gibt es eine zusätzliche externe Schicht, die anscheinend einer der Hauptvorteile ist, solche angenehmen Vorteile der technischen Umsetzung, die meiner Meinung nach hier vorhanden sein sollten. Sie sollte zwischen L2-Netzwerken und der Beacon-Kette erscheinen, die in Ethereum existiert. Übrigens sagen einige, dass der Begriff \"Beacon-Kette\" wieder ausstirbt und missverstanden wird, aber ich benutze ihn wirklich gerne in Analogie zur \"Relay-Kette\", einem Begriff aus dem Fahrplan von Ethereum.\n\nIn Polkadot gibt es eine externe Schicht, die es ermöglicht, oder besser gesagt, sie wurde erfunden, um viele Probleme zu lösen, die auftreten, wenn Sie L2 oder eine Reihe von Blockchains haben, die verbunden werden müssen. Auf dieser Ebene wird ein technischer Mechanismus zur Verteilung von Informationen implementiert, um diese in einem dezentralen Netzwerk verfügbar zu machen. Zusätzliche Algorithmen werden eingeführt, um nicht nur die Gültigkeit, sondern auch die Verfügbarkeit von Informationen durch Validatoren zu prüfen. Darüber hinaus gibt es einen Mechanismus, um in jeder Epoche einen Teil der Polkadot-Validatoren zufällig bestimmten Parachains zuzuweisen. Es gibt also nicht in jeder Epoche die gleichen Validatoren, die Parachains bedienen; Sie werden gemischt und in jeder Epoche an verschiedene Parachains gesendet. Bei der Übertragung eines Blocks vom externen Ring zum internen Ring werden die Validatoren unterwegs erneut überprüft und mit denen koordiniert, die der Parachain zugewiesen sind. Derzeit existiert dieser Prozess noch nicht, aber ich denke, dass er irgendwann auftauchen wird.\nUnd vielleicht geht es beim letzten Punkt um Collators, die heute recht interessant in Parachains implementiert sind. Sie können Konsens sein oder ohne Konsens existieren, aber tatsächlich funktioniert es. Was Fragen in L2-Netzwerken mit dezentralen Sequenzern betrifft oder wie Blöcke generiert und überprüft werden, bevor sie in der virtuellen Maschine abgelegt werden, sind dies separate Fragen für die Implementierung von Ethereum in einem heterogenen Format. An diesem Tag ist es meiner Meinung nach in Polkadot recht gut umgesetzt. Dies bedeutet jedoch nicht, dass Polkadot dem gesamten Planeten voraus ist und Ethereum niemals einholen wird. Obwohl es diese Architektur ist, die mich dazu reizt, weiterzuarbeiten und zu hoffen, dass sich Polkadot technologisch weiterhin gut entwickelt, denn so etwas habe ich in all den damit verbundenen Aspekten noch nicht gesehen.\n\nUnd vielleicht noch eine interessante Geschichte in diesem Teil der Vorlesung: Bisher können wir uns kaum vorstellen, dass es ordentliche Cross-Chain-Nachrichten zwischen L2-Netzwerken in Ethereum gibt. Vielleicht habe ich etwas in den Papieren übersehen, aber wenn man keinen externen Ring hat und Probleme wie Collators, Paravalidatoren und Datenverfügbarkeitsdienste nicht gelöst sind, ist es herausfordernd, darüber nachzudenken, wie zwei L2-Schichten kommunizieren können. Doch in Polkadot existiert das. Selbst horizontal, über die Relay-Kette, was bedeutet, dass man sicher eine Transaktion von einer Parachain zur anderen senden kann, ohne Brücken zwischen diesen beiden Parachains zu vertrauen. Dies ist eine weitere wichtige Funktionalität, die wahrscheinlich auf der Ebene der Verbindung von L2-Netzwerken implementiert werden muss. Smart Contracts in Ethereum kommunizieren gut. Wir haben viele Ketten von verknüpften Smart Contracts erstellt, bei denen einer den anderen auslöst. Dabei gibt es kein Problem. Aber wenn wir sagen, dass fast alle Anwendungen in ein heterogenes Netzwerk auf die L2-Ebene umziehen, höre ich, dass man, wenn man in einem bestimmten Bereich lebt, nicht herauskommen kann. Das ist nicht der Fall auf der Ebene der Parachains und der Implementierung in Polkadot. Beide Architekturen sind es wert, beobachtet zu werden, da meiner Meinung nach die technische Umsetzung dem Mainstream-Pfad folgt, ein globales Computer zu werden. Sie unterscheiden sich leicht, aber es gibt viele Ähnlichkeiten. Überall gibt es eine enorme Menge an Ingenieursarbeit. Wie wir sehen, bewegt sich die menschliche Zivilisation in Form einer Vielzahl von Forschern, Ingenieuren und wachsenden Entwicklern mit erheblichen Ressourcen für die weitere Entwicklung grob in die gleiche Richtung von der kleinsten Frühphase bis wahrscheinlich zur zukünftigen Einrichtung des Weltcomputers, alles auf den gleichen Gleisen.\n","fileInfo":{"path":"de/learn/world-computer/emergence-of-the-world-computer.md","name":"emergence-of-the-world-computer"},"defaultName":"World computer in your home","lastUpdate":null}},"context":{}}